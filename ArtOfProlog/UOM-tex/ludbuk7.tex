%%%%% Leonudi Book, Chapter 7, pp 107-124 %%%%%

\input wizzle
\input ludbumac
\hsize 12.4truecm
\vsize 18.2truecm
\input headline
\tolerance 3000
\chapnum=0\advance\chapnum by 6
\numberfirst
\startpage{107}

\chapb{Programming}{in Pure Prolog}
A major aim of logic programming is to enable the programmer to program
at a higher level. Ideally one should write axioms that define the
desired relations, maintaining ignorance of the way they are going to
be used by the execution mechanism. Current logic programming languages,
Prolog in particular, are still far away from allowing this ideal of
declarative programming. The specific, well-defined choices of how their
execution mechanisms approximate the abstract interpreter cannot be
ignored. Effective logic programming requires knowing and utilizing these
choices.\par
This chapter discusses the consequences of Prolog's execution model for
the logic programmer. New aspects of the programming task are introduced.
Not only must programmers come up with a correct and complete
axiomatization of a relation but they must also consider its execution
according to the model.\par
\sect{Rule Order}
Two syntactic issues, irrelevant for logic programs, are important to
consider when composing Prolog programs. The {\it rule order\/}, or {\it
clause order\/}, of clauses in each procedure must be decided. Also the
{\it goal order\/} of goals in the bodies of each clause must be
determined. The consequences of these decisions can be immense. There can
be orders of magnitude of difference in efficiency in the performance of
Prolog programs. In extreme though quite common cases, correct logic
programs will fail to give solutions because of nontermination.\par
{\it The rule order determines the order in which solutions are found\/}.
\par
Changing the order of rules in a procedure permutes the branches in any
search tree for a goal using that procedure. The search tree is traversed
depth-first. So permuting the branches causes a different order of
traversal of the search tree, and a different order of finding solutions.
The effect is clearly seen when using facts to answer an existential
query. With our biblical database and a query such as {\tt father(X,Y)?},
changing the order of facts will change the order of solutions found by
Prolog. Deciding how to order facts is not very important.\par
The order of solutions of queries solved by recursive programs is also
determined by the clause order. Consider Program~\Proyetanofam, a simple
biblical database together with a program for the relationship {\tt
ancestor}, repeated here as Program~\Proyetfamexa.
\midinsert
\halign{\hskip 40pt\lft{\tt #}\qquad&\lft{\tt #}\cr
parent(terach,abraham).&parent(abraham,isaac).\cr
parent(isaac,jacob).&parent(jacob,benjamin).\cr}\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
ancestor(X,Y) $\lar$ parent(X,Y).\cr
ancestor(X,Z) $\lar$ parent(X,Y), ancestor(Y,Z).\cr
\noalign{\bigskip}
{\bf Program \Proyetfamexa}{\rm :~~Yet another family example}\cr}
\endinsert\par
For the query {\tt ancestor(terach,X)?} with respect to Program
\Proyetfamexa, the solutions will be given in the order, {\tt X=abraham},
{\tt X=isaac}, {\tt X=jacob}, and {\tt X=benjamin}. If the rules defining
{\tt ancestor} are swapped, the solutions will appear in a different
order, namely, {\tt X=benjamin}, {\tt X=jacob}, {\tt X=isaac}, and {\tt
X=abraham}.\par
The different order of {\tt ancestor} clauses changes the order of
searching the implicit family tree. In one order, Prolog outputs
solutions as it goes along. With the other order, Prolog travels to the
end of the family tree and gives solutions on the way back. The desired
order of solutions is determined by the application, and the rule order
of {\tt ancestor} is chosen accordingly.\par
Changing the order of clauses for the {\tt member} predicate (Program
\Promemlis) also changes the order of search. As written, the program
searches the list until the desired element is found. If the order of the
clauses is reversed, the program always searches to the end of the list.
The order of solutions will also be affected, for example, responding to
the query {\tt member(X,\(1,2,3\))?}. In the standard order, the order of
solutions is intuitive: {\tt X=1}, {\tt X=2}, {\tt X=3}. With the rules
swapped, the order is {\tt X=3}, {\tt X=2}, {\tt X=1}. The order of
Program~\Promemlis\ is more intuitive and hence preferable.\par
When the search tree for a given goal has an infinite branch, the order
of clauses can determine if any solutions are given at all. Consider the
query {\tt append(Xs,\(c,d\),Ys)?} with respect to {\tt append}. As can
be seen from the search tree in Figure~\Figseatreinf, no solutions would
be given. If, however, the {\tt append} fact appeared before the {\tt
append} rule, an infinite number of pairs {\tt Xs,Ys} satisfying the
query would be given.\par
There is no consensus as to how to order the clauses of a Prolog
procedure. Clearly, the standard dictated in more conventional languages,
of testing for the termination condition before proceeding with the
iteration or recursion is not mandatory in Prolog. This is demonstrated
in Program~\Proapptwolis\ for {\tt append} as well as in other programs
in this book. The reason is that the recursive or iterative clause tests
its applicability by unification. This test is done explicitly and
independently of the other clauses in the procedure.\par
Clause order is more important for general Prolog programs than it is for
pure Prolog programs. Other control features, notably the cut to be
discussed in Chapter~11, depend significantly on the clause order. When
such constructs are used, clauses lose their independence and modularity,
and clause order becomes significant.\par
In this chapter, for the most part, the convention that the recursive
clauses precede the base clauses is adopted.\vskip 15pt\parno
{\bf Exercises for Section 7.1}\vskip 5pt\par
\offset{20pt}{(i)} Verify the order of solutions for the query {\tt
ancestor(abraham,X)?} with respect to Program~\Proyetfamexa, and its
variant with different rule order for {\tt ancestor}, claimed in the
text.\par
\offset{20pt}{(ii)} What is the order of solutions for the query {\tt
ancestor(X,benjamin)?} with respect to Program~\Proyetfamexa ? What if the
rule order for {\tt ancestor} were swapped?\par
\sect{Termination}
Prolog's depth-first traversal of search trees has a serious problem. If
the search tree of a goal with respect to a program contains an infinite
branch, the computation will not terminate. Prolog may fail to find a
solution to a goal, even though the goal has a finite computation.\par
Nontermination arises with recursive rules. Consider adding a
relationship {\tt married(Male,Female)} to our database of family
relationships. A sample fact from the biblical situation is {\tt
married(abraham,sarah)}. A user querying the {\tt married} relationship
should not care whether males or females are first, as the relationship
is commutative. The ``obvious" way of overcoming the commutativity is
adding a recursive rule {\tt married(X,Y) $\lar$ married(Y,X)}. If this
is added to the program, no computation involving {\tt married} would ever
terminate. For example, the trace of the query {\tt
married(abraham,sarah)?} is given in Figure~\Fignontercou.
\midinsert\vskip -0.2truecm
$$\vcenter{\halign{\lft{\tt #}\cr
married(X,Y) $\lar$ married(Y,X).\cr
married(abraham,sarah).\cr
\noalign{\vskip 5pt}
married(abraham,sarah)\cr
\qi married(sarah,abraham)\cr
\qii married(abraham,sarah)\cr
\qiii married(sarah,abraham)\cr
\qiiii $\ldots$\cr}}$$\medskip
\ctrline{{\bf  Figure \Fignontercou}:~~A nonterminating computation}
\endinsert\par
Recursive rules that have the recursive goal as the first goal in the
body are known as {\it left recursive\/} rules. The problematic {\tt
married} axiom is an example. Left recursive rules are inherently
troublesome in Prolog. They cause nonterminating computations if called
with inappropriate arguments.\par
The best solution to the problem of left recursion is avoidance. The {\tt
married} relationship used a left recursive rule to express
commutativity. Commutative relationships are best handled differently, by
defining a new predicate that has a clause for each permutation of the
arguments of the relationship. For the relationship {\tt married}, a new
predicate, {\tt are\_married(Person1,Person2)}, say, would be defined
using two rules:\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
are\_married(X,Y) $\lar$ married(X,Y).\cr
are\_married(X,Y) $\lar$ married(Y,X).\cr}\medno
Unfortunately, it is not generally possible to remove all occurrences of
left recursion. All the elegant minimal recursive logic programs shown in
Chapter~3 are left recursive, and can cause nontermination. However, the
appropriate analysis, using the concepts of domains and complete
structures introduced in Section~5.2, can determine which queries will
terminate with respect to recursive programs.\par
Let us consider an example, Program~\Proapptwolis\ for appending two
lists. The program for {\tt append} is everywhere terminating for the set
of goals whose first and/or last argument is a complete list. Any {\tt
append} query whose first argument is a complete list will terminate.
Similarly, all queries where the third argument is a complete list will
terminate. The program will also terminate if the first and/or third
argument is a ground term that is not a list. The behavior of {\tt
append} is best summed up by considering the queries that do not
terminate, namely, when both the first and third arguments are incomplete
lists that are unifiable.\par
The condition for when a query to Program~\Promemlis\ for {\tt member}
terminates is also stated in terms of incomplete lists. A query does not
terminate if the second argument is an incomplete list. If the second
argument of a query to {\tt member} is a complete list, the query
terminates.\par
Another guaranteed means of generating nonterminating computations, easy
to overlook, is circular definitions. Consider the pair of rules\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
parent(X,Y) $\lar$ child(Y,X).\cr
child(X,Y) $\lar$ parent(Y,X).\cr}\medno
Any computation involving {\tt parent} or {\tt child}, for example, {\tt
parent(haran,lot)?}, will not terminate. The search tree necessarily
contains an infinite branch, because of the circularity.\vskip 15pt\parno
{\bf Exercises for Section 7.2}\vskip 5pt\par
\offset{20pt}{(i)} Discuss the termination behavior of both programs in
Program~\Propresuflis\ determining prefixes and suffixes of lists.\par
\offset{20pt}{(ii)} Discuss the termination of Program~\Prodetsublis c
for {\tt sublist}.\par
\sect{Goal Order}
Goal order is more significant than clause order. It is the principal
means of specifying sequential flow of control in Prolog programs. The
programs for sorting lists, e.g., Program~\Proquicks\ for {\tt
quicksort}, exploit goal order to indicate the sequence of steps in the
sorting algorithms.\par
We first discuss goal order from the perspective of database programming.
The order of goals can affect the order of solutions. Consider the query
{\tt daughter(X,haran)?} with respect to a variant of Program
\Probibfamrel, where the order of the facts {\tt female(milcah)} and {\tt
female(yiscah)} is interchanged. The two solutions are given in the order
{\tt X=milcah}, {\tt X=yiscah}. If the goal order of the {\tt daughter}
rule were changed to be 
{\tt daughter(X,Y) $\lar$ female(X),father(Y,X).}, 
the order of the solutions to the query, given the same database, would
be {\tt X=yiscah}, {\tt X=milcah}.\par
The reason that the order of goals in the body of a clause affects the
order of solutions to a query is different from the reason that the
order of rules in a procedure affects the solution order. Changing rule
order does not change the search tree that must be traversed for a given
query. The tree is just traversed in a different order. Changing goal
order changes the search tree.\par
{\it Goal order determines the search tree\/}.\par
Goal order affects the amount of searching the program does in solving a
query by determining which search tree is traversed. Consider the two
search trees for the query {\tt son(X,haran)?}, given in Figure
\Figtwoseatre. They represent two different ways of finding a solution.
In the first case, solutions are found by searching for children of {\tt
haran} and checking if they are male. The second case corresponds to the
rule for {\tt son} being written with the order of the goals in its body
swapped, namely, {\tt son(X,Y) $\lar$ male(X), parent(Y,X)}. Now the
query is solved by searching through all the males in the program and
checking if they are children of {\tt haran}. If there were many {\tt
male} facts in the program, more search would be involved. For other
queries, for example, {\tt son(sarah,X)?}, the reverse order has
advantages. Since {\tt sarah} is not male, the query would fail more
quickly.\par
The optimal goal order of Prolog programs varies with different uses.
Consider the definition of {\tt grandparent}. There are two possible
rules:\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
grandparent(X,Z) $\lar$ parent(X,Y), parent(Y,Z).\cr
grandparent(X,Z) $\lar$ parent(Y,Z), parent(X,Y).\cr}\medno
If you wish to find someone's grandson with the {\tt grandfather}
relationship with a query such as {\tt grandparent(abraham,X)?}, the
first of the rules searches more directly. If looking for someone's
grandparent with a query such as {\tt grandparent(X,isaac)?}, the
second rule finds the solution more directly. If efficiency is
important, then it is advisable to have two distinct relationships,
{\tt grandparent} and {\tt grandchild}, to be used appropriately at
the user's discretion.\par 
In contrast to rule order, goal order can determine whether computations
terminate. Consider the recursive rule for {\tt ancestor}:\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
ancestor(X,Y) $\lar$ parent(X,Z), ancestor(Z,Y).\cr}\medno
If the goals in the body are swapped, the {\tt ancestor} program becomes
left recursive, and all Prolog computations with {\tt ancestor} are
nonterminating.\par
The goal order is also important in the recursive clause of the quicksort
algorithm in Program~\Proquicks:\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
quicksort([X$\mid$Xs],Ys) $\lar$\cr
\qi partition(Xs,X,Littles,Bigs),\cr
\qi quicksort(Littles,Ls),\cr
\qi quicksort(Bigs,Bs),\cr
\qi append(Ls,[X$\mid$Bs],Ys).\cr}\medno
The list should be partitioned into its two smaller pieces before
recursively sorting the pieces. If, for example, the order of the {\tt
partition} goal and the recursive sorting goal is swapped, no
computations terminate.\par
We next consider Program~3.16a for reversing a list:\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
reverse([~],[~]).\cr
reverse([X$\mid$Xs],Zs) $\lar$ reverse(Xs,Ys), append(Ys,[X],Zs).\cr}\medno
The goal order is significant. As written, the program terminates with
goals where the first argument is a complete list. Goals where the first
argument is an incomplete list give nonterminating computations. If the
goals in the recursive rule are swapped, the determining factor of the
termination of {\tt reverse} goals is the second argument. Calls to {\tt
reverse} with the second argument a complete list terminate. They do not
terminate if the second argument is an incomplete list.\par
A subtler example comes from the definition of the predicate {\tt
sublist} in terms of two {\tt append} goals, specifying the sublist as a
suffix of a prefix, as given in Program~\Prodetsublis e. Consider the
query {\tt sublist(\(2,3\),\(1,2,3,4\))?} with respect to the program.
The query is reduced to {\tt
append(AsXs,Bs,\(1,2,3,4\)),append(}\linebreak
{\tt As,\(2,3\),AsXs)?}. This has a finite search tree, and the initial
query succeeds. If Program~\Prodetsublis e had its goals reversed, the
initial query would be reduced to {\tt
append(As,\(2,3\),AsXs),append(AsXs,Bs,\(1,2,3,4\))?}. This leads to a
nonterminating computation because of the first goal, as illustrated
in Figure~\Figseatreinf.\par
A useful heuristic for goal order can be given for recursive programs
with tests such as arithmetic comparisons, or determining whether two
constants are different. The heuristic is to place the tests as early as
possible. An example comes in the program for {\tt partition}, which is
part of Program~\Proquicks. The first recursive rule is\medskip
\halign{\hskip 20pt\lft{\tt #}\cr
partition([X$\mid$Xs],Y,[X$\mid$Ls],Bs) $\lar$ X $\le$ Y,
partition(Xs,Y,Ls,Bs).\cr}\medno
The test {\tt X $\le$ Y} should go before the recursive call. This leads
to a smaller search tree.\par
In Prolog programming (in contrast, perhaps, to life in general) our
goal is to fail as quickly as possible. Failing early prunes the search
tree and brings us to the right solution sooner.\vskip 15pt\parno
{\bf Exercises for Section 7.3}\vskip 5pt \par
\offset{20pt}{(i)} Consider the goal order for Program~\Prodetsublis e
defining a sublist of a list as a suffix of a prefix. Why is the order of
the {\tt append} goals in Program~\Prodetsublis e preferable?
(Hint:~~Consider the query {\tt sublist(Xs,[a,b,c])?}.)\par
\offset{20pt}{(ii)} Discuss the clause order, goal order, and termination
behavior for {\tt substitute}, posed as Exercise~3.3(i).\par
\sect{Redundant Solutions}
An important issue when composing Prolog programs, irrelevant for logic
programs, is the redundancy of solutions to queries. The meaning of a
logic program is the set of ground goals deducible from it. No
distinction is made between whether a goal in the meaning could be
deduced uniquely from the program, or whether it could be deduced in
several distinct ways. This distinction is important for Prolog when
considering the efficiency of searching for solutions. Each possible
deduction means an extra branch in the search tree. The bigger the search
tree, the longer a computation will take. It is desirable in general to
keep the size of the search tree as small as possible.\par
Having a redundant program may cause, in an extreme case, exponential
increase in runtime, in the event of backtracking. If a conjunction of
{\it n\/} goals is solved, and each goal has one redundant solution, then
in the event of backtracking, the conjunction may generate 2$^n$
solutions, thus possibly changing a polynomial-time program (or even a
linear one) to be exponential.\par
One way for redundancy to occur in Prolog programs is by covering the
same case with several rules. Consider the following two clauses defining
the relation {\tt minimum}.\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
minimum(X,Y,X) $\lar$  X $\le$ Y.\cr
minimum(X,Y,Y) $\lar$ Y $\le$ X.\cr}\medno
The query {\tt minimum(2,2,M)?} with respect to these two clauses has a
unique solution {\tt M=2}, which is given twice; one is redundant.\par
Careful specification of the cases can avoid the problem. The second
clause can be changed to\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
minimum(X,Y,Y) $\lar$ Y $<$ X.\cr}\medno
Now only the first rule covers the case when the two numbers have equal
values.\par
Similar care is necessary with the definition of {\tt partition} as part
of Program~\Proquicks\ for {\tt quicksort}. The programmer must ensure
that only one of the recursive clauses for {\tt partition} covers the
case when the number being compared is the same as the number being used
to split the list.\par
Another way redundancy appears in programs is by having too many special
cases. Some of these can be motivated by efficiency. An extra fact can be
added to Program~\Proapptwolis\ for {\tt append}, namely, {\tt
append(Xs,[~],Xs)}, to save recursive computations when the second
argument is an empty list. In order to remove redundancy, each of the
other clauses for {\tt append} would have to cover only lists with at
least one element as their second argument.\par
We illustrate these points when composing Program~\Promerordlis\ for the
relation {\tt merge(Xs,Ys,Zs)}, which is true if {\tt Xs} and {\tt Ys}
are lists of integers sorted in ascending order and {\tt Zs} is the
ordered list resulting from merging them.
\midinsert
\halign{\hskip 40pt\lft{\tt #}\cr
{\it merge\/}({\it Xs,Ys,Zs\/}) $\lar$\cr
\qi {\it Zs\/} {\rm is an ordered list of integers obtained from}\cr
\qi {\rm merging the ordered lists of integers} {\it Xs\/} {\rm and} {\it
Ys\/}{\rm .}\cr
\noalign{\medskip}
merge([X$\mid$Xs],[Y$\mid$Ys],[X$\mid$Zs]) $\lar$\cr
\qi X $<$ Y, merge(Xs,[Y$\mid$Ys],Zs).\cr
merge([X$\mid$Xs],[Y$\mid$Ys],[X,X$\mid$Zs]) $\lar$\cr
\qi X =:= Y, merge(Xs,Ys,Zs).\cr
merge([X$\mid$Xs],[Y$\mid$Ys],[Y$\mid$Zs]) $\lar$\cr
\qi X $>$ Y, merge([X$\mid$Xs],Ys,Zs).\cr
merge([~],[X$\mid$Xs],[X$\mid$Xs]).\cr
merge(Xs,[~],Xs).\cr
\noalign{\bigskip}
{\bf Program \Promerordlis}{\rm :~~Merging ordered lists}\cr}
\endinsert\par
There are three separate recursive clauses. They cover the three possible
cases: when the head of the first list is less than, equal to, or greater
than the head of the second list. We discuss the predicates $<$, $=:=$, and
$>$  in Chapter~8. Two cases are needed when the elements in either list
have been exhausted. Note that we have been careful that the goal {\tt
merge([~],[~],[~])} is covered by only one fact, the bottom one.\par
Redundant computations occur when using {\tt member} to find whether a
particular element occurs in a particular list, and there are multiple
occurrences of the particular element being checked for in the list. For
example, the search tree for the query {\tt member(a,[a,b,a,c])} would
have two success nodes.\par
The redundancy of previous programs was removed by a careful
consideration of the logic. In this case, the {\tt member} program is
correct. If we want a different behavior, the solution is to
compose a modified version of {\tt member}.
\topin
\halign{\hskip 40pt\lft{\tt #}\cr
{\it member\_check\/}({\it X,Xs\/}) $\lar$\cr
\qi {\it X\/} {\rm is a member of the list} {\it Xs\/}{\rm .}\cr
\noalign{\medskip}
member\_check(X,\(X$\mid$Xs\)).\cr
member\_check(X,\(Y$\mid$Ys\)) $\lar$ X $\ne$ Y, member\_check(X,Ys).\cr
\noalign{\bigskip}
{\bf  Program~\Prochelismem}{\rm :~~Checking for list membership}\cr}
\endin\par
Program~\Prochelismem\ defines the relation {\tt member\_check(X,Xs)}
which checks whether an element {\tt X} is a member of a list {\tt
Xs}. The program is a variant of Program~\Promemlis\ for {\tt member}
that adds a test to the recursive clause. It has the same meaning but,
as a Prolog program, it behaves differently. Figure~\Figvarseatre\
shows the difference between the search trees for the identical query
to the two programs. The left tree is for the
goal {\tt member(a,\(a,b,a,c\))} with respect to Program~\Promemlis. Note
there are two success nodes. The right tree is for the goal {\tt
member\_check(a,\(a,b,a,c\))} with respect to Program~\Prochelismem. It
has only one success node.\par
\midinsert\vskip -0.2truecm
$$\vcenter{\halign{\ctr{\tt #}\qquad&\ctr{\tt #}\cr
member(a,[a,b,a,c])&member\_check(a,[a,b,a,c])\cr
\noalign{\vskip 10pt}
{\it true}\quad member(a,[b,a,c])&{\it true}\quad a$\ne$a,
member\_check(a,[b,a,c])\cr
\noalign{\vskip 10pt}
member(a,[a,c])&\cr
\noalign{\vskip 10pt}
{\it true}\quad member(a,[c])&\cr
\noalign{\vskip 10pt}
member(a,[~])&\cr}}$$\medskip
\ctrline{{\bf Figure \Figvarseatre}:~~Variant search trees}
\endinsert\par
We restrict use of Program~\Prochelismem\ to queries where both arguments
are ground. This is because of the way $\ne$ is implemented in Prolog, 
discussed in Section~11.3.\par
\sect{Recursive Programming in Pure Prolog}
Lists are a very useful data structure for many applications written in
Prolog. In this section, we revise several logic programs of Sections 3.2
and 3.3 concerned with list processing. The chosen clause and goal orders
are explained, and their termination behavior presented. The section also
discusses some new examples. Their properties are analyzed, and a
reconstruction offered of how they are composed.\par
Programs \Promemlis\ and \Proapptwolis for {\tt member} and {\tt append},
respectively, are correct Prolog programs as written. They are both
minimal recursive programs, so there is no issue of goal order. They are
in their preferred clause order, the reasons for which have been
discussed earlier in this chapter. The termination of the programs was
discussed in Section~7.2.\par
Program~\Proselelelis\ for {\tt select} is analogous to the program for
{\tt member}:\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
select(X,[X$\mid$Xs],Xs).\cr
select(X,[Y$\mid$Ys],[Y$\mid$Zs]) $\lar$ select(X,Ys,Zs).\cr}\medno
The analysis of {\tt select} is similar to the analysis of {\tt member}.
There is no issue of goal order because the program is minimal
recursive. The clause order is chosen to reflect the intuitive order
of solutions to queries such as {\tt select(X,[a,b,c],Xs)}, namely, {\tt
$\{$X=a,Xs=[b,c]$\}$,$\{$X=b,Xs=\(a,c]$\}$,$\{$X=c,Xs=[a,b]$\}$}. The
first solution is the result of choosing the first element, and so forth.
The program terminates unless both the second and third arguments are
incomplete lists.\par
A variant of {\tt select} is obtained by adding the test {\tt X $\ne$ Y}
in the recursive clause. As before, we assume that $\ne$ is only defined
for ground arguments. The variant is given as Program~\Proselfirocc\
defining the relation {\tt select\_first(X,Xs,Ys)}. Programs
\Promemlis\ and \Prochelismem\ defining {\tt member} and {\tt
member\_check} have the same meaning. Program~\Proselfirocc, in contrast,
has a different meaning from Program~\Proselelelis. The goal {\tt
select(a,\(a,b,a,c\),\(a,b,c\))} is in the meaning of {\tt select},
whereas {\tt select\_first(a,\(a,b,a,c\),\(a,b,c\))} is not in the
meaning of {\tt select\_first}.
\midinsert
\halign{\hskip 40pt\lft{\tt #}\cr
{\it select\_first\/}({\it X,Xs,Ys\/}) $\lar$\cr
\qi {\it Ys\/} {\rm is the list obtained by removing the}\cr
\qi {\rm first occurrence of} {\it X\/} {\rm from the list} {\it
Xs\/}{\rm .}\cr
\noalign{\medskip}
select\_first(X,\(X$\mid$Xs\),Xs).\cr
select\_first(X,\(Y$\mid$Ys\),\(Y$\mid$Zs\)) $\lar$\cr
\qi X $\ne$ Y, select\_first(X,Ys,Zs).\cr
\noalign{\bigskip}
{\bf Program \Proselfirocc}{\rm :~~Selecting the first occurrence of an
element from a list}\cr}
\endinsert\par
The next program considered is Program~\Propersor\ for {\tt permutation}.
The order of clauses, analogously to the clause order for {\tt append},
reflects the more likely mode of use:\medskip
\halign{\hskip 20pt\lft{\tt #}\cr
permutation(Xs,[X$\mid$Ys]) $\lar$ select(X,Xs,Zs),
permutation(Zs,Ys).\cr
permutation([~],[~]).\cr}\medno
The goal order and the termination behavior of {\tt permutation} are
closely related. Computations of {\tt permutation} goals where the first
argument is a complete list will terminate. The query calls {\tt select}
with its second argument a complete list, which terminates generating a
complete list as its third argument. Thus there is a complete list for
the recursive {\tt permutation} goal. If the first argument is an
incomplete list, the {\tt permutation} query will not terminate, because
it calls a {\tt select} goal that will not terminate. If the order of the
goals in the recursive rule for {\tt permutation} is swapped, the second
argument of a {\tt permutation} query becomes the significant one for
determining termination. If it is an incomplete list, the computation
will not terminate; otherwise it will.\par
A useful predicate using $\ne$ is {\tt nonmember(X,Ys)} which is true if
{\tt X} is not a member of a list {\tt Ys}. Declaratively the definition
is straightforward: An element is a nonmember of a list if it is not the
head and is a nonmember of the tail. The base case is that any element is
a nonmember of the empty list. This program is given as Program
\Prononmemlis.
\midinsert
\halign{\hskip 40pt\lft{\tt #}\cr
{\it nonmember\/}({\it X,Xs\/}) $\lar$\cr
\qi {\it X\/} {\rm is not a member of the list} {\it Xs\/}{\rm .}\cr
\noalign{\medskip}
nonmember(X,[Y$\mid$Ys]) $\lar$ X $\ne$ Y, nonmember(X,Ys).\cr
nonmember(X,[~]).\cr
\noalign{\bigskip}
{\bf Program \Prononmemlis}{\rm :~~Nonmembership of a list}\cr}
\endinsert\par
Because of the use of $\ne$, {\tt nonmember} is restricted to ground
instances. This is sensible intuitively. There are arbitrarily many
elements that are not elements of a given list, and also arbitrarily
many lists not containing a given element. Thus the behavior of Program
\Prononmemlis\ with respect to these queries is largely irrelevant.\par
The clause order of {\tt nonmember} follows the convention of the
recursive clause preceding the fact. The goal order uses the heuristic of
putting the test before the recursive goal.\par
We reconstruct the composition of two programs concerned with the
subset relation.  Program~\Protesforsub\ defines a relation based on
Program~\Promemlis\ for {\tt member}, and Program~\Protesforsus\
defines a relation based on Program~\Proselelelis\ for {\tt select}.
Both consider the occurrences of the elements of one list in a second list.
\topin
\halign{\hskip 40pt\lft{\tt #}\cr
{\it members\/}({\it Xs,Ys\/}) $\lar$\cr
\qi {\rm Each element of the list} {\it Xs\/} {\rm is a member of the
list} {\it Ys\/}{\rm .}\cr
\noalign{\medskip}
members(\(X$\mid$Xs\),Ys) $\lar$ member(X,Ys), members(Xs,Ys).\cr
members(\(~\),Ys).\cr
\noalign{\bigskip}
{\bf  Program \Protesforsub}{\rm :~~Testing for a subset}\cr}\vskip
0.6truecm
\halign{\hskip 40pt\lft{\tt #}\cr
{\it selects\/}({\it Xs,Ys\/}) $\lar$\cr
\qi {\rm The list} {\it Xs\/} {\rm is a subset of the list} {\it
Ys\/}{\rm .}\cr
\noalign{\medskip}
selects(\(X$\mid$Xs\),Ys)
$\lar$ select(X,Ys,Ys1), selects(Xs,Ys1).\cr
selects(\(~\),Ys).\cr
\noalign{\vskip 5pt}
select(X,Ys,Zs) $\lar$ {\rm See Program \Proselelelis}.\cr
\noalign{\bigskip}
{\bf  Program \Protesforsus}{\rm :~~Testing for a subset}\cr}
\endin\par
Program~\Protesforsub\ defining {\tt members(Xs,Ys)} ignores the
multiplicity of elements in the lists. For example, {\tt
members(\(b,b\),\(a,b,c\))} is in the meaning of the program. There are
two occurrences of {\tt b} in the first list, but only one in the second.
\par
Program~\Protesforsub\ is also restrictive with respect to termination.
If either the first or the second argument of a {\tt members} query is an
incomplete list, the program will not terminate. The second argument must
be a complete list because of the call to {\tt member}, while the first
argument must also be complete, since that is providing the recursive
control. The query {\tt members(Xs,[1,2,3])?} asking for subsets of a
given set does not terminate. Since multiple copies of elements are
allowed in {\tt Xs}, there are an infinite number of solutions, and hence
the query should not terminate.\par
Both these limitations are avoided by Program~\Protesforsus. The revised
relation is {\tt selects(Xs,Ys)}. Goals in the meaning of Program
\Protesforsus\ have at most as many copies of an element in the first
list as appear in the second. Related to this property, Program
\Protesforsus\ terminates whenever the second argument is a complete
list. A query such as {\tt selects(Xs,[a,b,c])} has as solution all the
subsets of a given set.\par
We now consider a different example: translating a list of English words,
word for word, into a list of French words. The relation is {\tt
translate(Words,Mots)}, where {\tt Words} is a list of English words and
{\tt Mots} the corresponding list of French words. Program~\Protraworwor\
performs the translation. It assumes a dictionary of pairs of
corresponding English and French words, the relation scheme being {\tt
dict(Word,Mot)}. The translation is very naive, ignoring issues of
number, gender, subject-verb agreement, and so on. Its range is solving a
query such as {\tt translate(\(the,dog,chases,the,cat\)),X)?} with
solution {\tt X=\(le,chien,chasse,le,chat\)}. This program can be used in
multiple ways. English sentences can be translated to French, French ones
to English, or two sentences can be checked to see if they are correct
mutual translations.
\midinsert
\halign{\hskip 40pt\lft{\tt #}\cr
{\it translate\/}({\it Words,Mots\/}) $\lar$\cr
\qi {\it Mots\/} {\rm is a list of French words that is the}\cr
\qi {\rm translation of the list of English words} {\it Words\/}{\rm .}\cr
\noalign{\medskip}
translate(\(Word$\mid$Words\),\(Mot$\mid$Mots\)) $\lar$\cr
\qi dict(Word,Mot), translate(Words,Mots).\cr
translate(\(~\),\(~\)).\cr}\medskip
\halign{\hskip 40pt\lft{\tt #}\qquad&\lft{\tt #}\cr
dict(the,le).&dict(dog,chien).\cr
dict(chases,chasse).&dict(cat,chat).\cr}\bigskip
\halign{\hskip 40pt\lft{#}\cr
{\bf Program \Protraworwor}:~~Translating word for word\cr}
\endinsert\par
Program~\Protraworwor\ is a typical program performing {\it mapping\/},
that is, converting one list to another by applying some function to each
element of the list. The clause order has the recursive rule(s) first,
and the goal order calls {\tt dict} first, so as not to be left
recursive.\par
We conclude this section with a discussion of the use of data structures
in Prolog programs. Data structures are handled somewhat differently in
Prolog than in conventional programming languages. Rather than having a
global structure, all parts of which are accessible, the programmer
specifies logical relations between various substructures of the
data.\par
Taking a more procedural view, in order to build and modify structures,
the Prolog programmer must pass the necessary fields of the structure to
subprocedures. These fields are used and/or acquire values during the
computation. Assignment of values to the structures happens via
unification.\par
Let us look more closely at a generic example --- producing a single
output from some given input. Examples are the standard use of  {\tt
append}, joining two lists together to get a third, and using Program
\Protraworwor\ to translate a list of English words into French. The
computation proceeds recursively. The initial call instantiates the
output to be an incomplete list {\tt [X$\mid$Xs]}. The head {\tt X} is
instantiated by the call to the procedure, often in unification with the
head of the clause. The tail {\tt Xs} is progressively instantiated
while solving the recursive call. The structure becomes fully
instantiated with the solution of the base case and the termination of
the computation.\par
Consider appending the list {\tt [c,d]} to the list {\tt [a,b\)}, as
illustrated in Figure~\Figtraapptwo. The output {\tt Ls=\(a,b,c,d\)} is
constructed in stages, as {\tt Ls=\(a$\mid$Zs\)}, {\tt Zs=\(b$
\mid$Zs1\)}, and finally {\tt Zs1=\(c,d\)}, when the base fact of {\tt
append} is used. Each recursive call partially instantiates the
originally incomplete list. Note that the recursive calls to {\tt append}
do not have access to the list  being computed. This is a {\it top-down
construction} of recursive structures and is typical of programming in
Prolog.\par
The top-down construction of recursive data structures has one
limitation. Pieces of the global data structure cannot be referred to
deeper in the computation. This is illustrated in a program for the
relation {\tt no\_doubles(XXs,Xs)}, which is true if {\tt Xs} is a list of
all the elements appearing in the list {\tt XXs} with all duplicates
removed.\par
Consider trying to compose {\tt no\_doubles} top-down. The head of the
recursive clause will be\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
no\_doubles([X$\mid$Xs],$\cdots$) $\lar$\cr}\medno
where we need to fill in the blank. The blank is filled by calling {\tt
no\_doubles} recursively on {\tt Xs} with output {\tt Ys} and integrating
{\tt Ys} with {\tt X}. If {\tt X} has not appeared in the output so far,
then it should be added, and the blank will be {\tt [X$\mid$Ys]}. If {\tt
X} has appeared, then it should not be added and the blank is {\tt Ys}.
This cannot be easily said. There is no way of knowing what the output is
so far.\par
A program for {\tt no\_doubles} can be composed by thinking differently
about the problem. Instead of determining whether an element has already
appeared in the output, we can determine whether it will appear. Each
element {\tt X} is checked to see if it appears again in the tail of the
list {\tt Xs}. If {\tt X} appears, then the result is {\tt Ys}, the
output of the recursive call to {\tt no\_doubles}. If {\tt X} does not
appear, then it is added to the recursive result. This version of {\tt
no\_doubles} is given as Program~\Proremduplis. It uses 
Program~\Prononmemlis\ for {\tt nonmember}.
\topin
\halign{\hskip 40pt\lft{\tt #}\cr
{\it no\_doubles\/}({\it Xs,Ys\/}) $\lar$\cr
\qi {\it Ys\/} {\rm is the list obtained by removing}\cr
\qi {\rm duplicate elements from the list} {\it Xs\/}{\rm .}\cr
\noalign{\medskip}
no\_doubles([X$\mid$Xs],Ys) $\lar$\cr
\qi member(X,Xs), no\_doubles(Xs,Ys).\cr
no\_doubles([X$\mid$Xs],[X$\mid$Ys]) $\lar$\cr
\qi nonmember(X,Xs), no\_doubles(Xs,Ys).\cr
no\_doubles([~],[~]).\cr
\noalign{\vskip 5pt}
nonmember(X,Xs) $\lar$ {\rm See Program \Prononmemlis.}\cr
\noalign{\bigskip}
{\bf Program \Proremduplis}{\rm :~~Removing duplicates from a list}\cr}
\endin\par
A problem with Program~\Proremduplis\ is that the list without duplicates
may not have the elements in the desired order. For example, {\tt
no\_doubles([a,b,c,b],Xs)?} has the solution {\tt Xs=[a,c,b]}, where the
solution {\tt Xs=[a,b,c]} may be preferred. This latter result is
possible if the program is rewritten. Each element is deleted from the
remainder of the list as it is found. In  terms of Program~\Proremduplis,
this is done by replacing the two recursive calls by a rule\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
no\_doubles([X$\mid$Xs],[X$\mid$Ys]) $\lar$\cr
\qi delete(X,Xs,Xs1), no\_doubles(Xs1,Ys).\cr}\medno
The new program builds the output top-down. However, it is inefficient for
large lists, as will be discussed in Chapter~13. Briefly, each call to
{\it delete\/} rebuilds the whole structure of the list.\par
The alternative to building structures top-down is building them
bottom-up. A simple example of bottom-up construction of data
structures is Program~\Prorevlis b for reversing a list:\medskip
\halign{\hskip 40pt\lft{\tt #}\cr
reverse(Xs,Ys) $\lar$ reverse(Xs,\(~\),Ys).\cr
\noalign{\vskip 5pt}
reverse(\(X$\mid$Xs\),Revs,Ys) $\lar$ reverse(Xs,\(X$\mid$Revs\),Ys).\cr
reverse(\(~\),Ys,Ys).\cr}\medno
An extra argument is added to {\tt reverse/2} and used to accumulate the
values of the reversed list as the computation proceeds. This procedure
for {\tt reverse} builds the output list bottom-up rather than top-down.
In the trace in Figure~\Figtrarevcom\ solving the goal {\tt
reverse([a,b,c],Xs)}, the successive values of the middle argument of the
calls to {\tt reverse/3 [~]}, {\tt [a]}, {\tt [b,a]}, and {\tt [c,b,a]}
represent the structure being built.
\midinsert\vskip -0.2truecm
$$\vcenter{\halign{\lft{\tt #}\cr
reverse([a,b,c],Xs)\cr
\hbox{\hskip 10pt reverse([a,b,c],[~],Xs)}\cr
\qi reverse([b,c],[a],Xs)\cr
\hbox{\hskip 30pt reverse([c],[b,a],Xs)}\cr
\qii reverse([~],[c,b,a],Xs)\quad Xs=[c,b,a]\cr
\hbox{\hskip 50pt {\it true}}\cr}}$$\medskip
\ctrline{{\bf Figure \Figtrarevcom}:~~Tracing a {\tt reverse} computation}
\endinsert\par
A bottom-up construction of structures allows access to the partial
results of the structure during the computation. Consider a relation {\tt
nd\_reverse(Xs,Ys)} combining the effects of {\tt no\_doubles} and {\tt
reverse}. The meaning of {\tt nd\_reverse} is that {\tt Ys} is a list of
elements in {\tt Xs} in reverse order and with duplicates removed.
Analogously to {\tt reverse}, {\tt nd\_reverse} calls {\tt nd\_reverse/3}
with an extra argument that builds the result bottom-up. This argument is
checked to see whether a particular element appears, rather than checking
the tail of the list as in Program~\Proremduplis\ for {\tt no\_doubles}.
The program is given as Program~\Prorevwnodup.
\midinsert
\halign{\hskip 40pt\lft{\tt #}\cr
{\it nd\_reverse\/}({\it Xs,Ys\/}) $\lar$\cr
\qi {\it Ys\/} {\rm is the reversal of the list obtained by}\cr
\qi {\rm removing duplicate elements from the list} {\it Xs\/}{\rm .}\cr
\noalign{\medskip}
nd\_reverse(Xs,Ys) $\lar$ nd\_reverse(Xs,[~],Ys).\cr
\noalign{\vskip 5pt}
nd\_reverse([X$\mid$Xs],Revs,Ys) $\lar$\cr
\qi member(X,Revs), nd\_reverse(Xs,Revs,Ys).\cr
nd\_reverse([X$\mid$Xs],Revs,Ys) $\lar$\cr
\qi nonmember(X,Revs), nd\_reverse(Xs,[X$\mid$Revs],Ys).\cr
nd\_reverse([~],Ys,Ys).\cr
\noalign{\vskip 5pt}
nonmember(X,Xs) $\lar$ {\rm See Program \Prononmemlis.}\cr
\noalign{\bigskip}
{\bf Program \Prorevwnodup}{\rm :~~Reversing with no duplicates}\cr}
\endinsert\par
We emphasize the characteristics of bottom-up construction illustrated
here. One argument behaves as an accumulator of the final data structure.
It is augmented in the recursive call, so that the more complex version
is in the body of the clause rather than in its head. This contrasts with
top-down construction, where the more complex version of the data
structure being built is in the head of the clause. Another argument is
used solely for returning the output, namely, the final value of the
accumulator. It is instantiated with the satisfaction of the base fact.
The argument is explicitly carried unchanged in the recursive call.\par
The technique of adding an accumulator to a program can be
generalized. It is used in Chapter~8 discussing Prolog programs
for arithmetic. Accumulators can also be viewed as a special case of
incomplete data structures, as is discussed in Chapter~15.
\vskip 15pt\parno
{\bf Exercise for Section 7.5}\vskip 5pt\par
\offset{20pt}{(i)} Write Program \Proremduplis\ for {\tt no\_doubles},
building the structure bottom-up.\endpage
\sect{Background}
Prolog was envisaged as a first approximation to logic programming, which
would be superseded by further research. Its control has always been
acknowledged as being limited and naive. An oft-cited slogan, credited to
Kowalski (1979b), is ``Algorithm = Logic + Control." The particular
control provided in pure Prolog was intended as just one solution on the
path to declarative programming and intelligent control. Time has shown
otherwise. The control of Prolog has proven adequate for a large range of
applications, and the language has not only endured but has blossomed.
\par
Nonetheless, logic programming researchers have investigated other forms
of control. For example, LOGLISP (Robinson and Sibert, 1982) has
breadth-first traversal of the search tree, and IC-Prolog (Clark and
McCabe, 1979) has co-routining. MU-Prolog (Naish, 1986) allows
suspension to provide a correct implementation of negation and to
prevent the computation from searching infinite branches in certain
cases. Wait declarations are generated (Naish, 1985b)\linebreak
that are related to the conditions on termination of Prolog programs
given in Section~7.2.\par
A methodology for systematically constructing simple Prolog programs is
given in Deville (1990). Essential to Deville's methods are
specifications, a subject touched upon in Section~13.3.\par
Analysis of Prolog programs, and logic programs more generally, has
become a hot topic of research. Most analyses are based on some form of
{\it abstract interpretation\/}, a topic beyond the scope of this book.
The initial work in Prolog can be found in Mellish (1985), and a view of
leading research groups can be found in a special issue of the {\it Journal of
Logic Programming} (1993).\par
Extensive work has also appeared recently on analyzing termination of
Prolog programs. A starting place for this topic is Pl\"umer (1990).\par
\bye

