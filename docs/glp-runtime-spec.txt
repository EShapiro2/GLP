# GLP Runtime System Specification for Dart Implementation v2.1

## Overview

The GLP runtime system executes bytecode on a Dart-based virtual machine that leverages Dart's native features for memory management, scheduling, and concurrency. Unlike the FCP abstract machine which manages its own process queue and garbage collection, this runtime delegates these responsibilities to Dart while focusing on GLP-specific semantics: reader/writer variables, suspension management, and SRSW enforcement.

## System Architecture

### Core Runtime Components

The runtime consists of several interconnected subsystems that collectively implement GLP's execution model.

#### Goal Scheduler
The scheduler manages goals using Dart's event loop with two-level fairness:

**Intra-GLP fairness**: Active goals are queued as Dart microtasks in FIFO order. Both `spawn` and `requeue` place goals at the tail of the queue, ensuring fair scheduling among concurrent GLP goals. 

**System-level fairness**: To prevent GLP computations from starving the event queue (timers, I/O, UI), the runtime implements bounded tail recursion following FCP's approach. Each goal has a tail-recursion budget counter that decrements on each `requeue` operation. When the counter reaches zero, the goal is scheduled via `Timer.run()` instead of `scheduleMicrotask()`, yielding to the event queue before continuing. This prevents compute-intensive tail-recursive goals from monopolizing the microtask queue.

Suspended goals are stored in a suspension table indexed by reader variables, with each entry containing the suspended goal's state and its suspension set. Failed goals are retained for debugging and error reporting but removed from active scheduling. The scheduler uses Dart's `scheduleMicrotask()` for goal activation when the tail-recursion budget is positive, and `Timer.run()` when yielding is required, eliminating the need for explicit time-slicing as in FCP.

#### Memory Management
The runtime leverages Dart's garbage collector rather than implementing stop-and-copy collection as in FCP. The heap is implemented as a Dart List of tagged cells, growing dynamically as needed. Stack frames are Dart objects that participate in standard garbage collection. The variable table uses weak references where appropriate to avoid preventing collection of abandoned variables. This design significantly simplifies the runtime compared to FCP's explicit memory management while maintaining efficient execution.

#### Unification Engine
The writer MGU algorithm forms the core of goal reduction. Unlike standard Prolog unification, it enforces GLP's asymmetric variable semantics where only writers can be bound, readers can only be verified, and writer-to-writer bindings are prohibited. The engine maintains a mode flag (READ/WRITE) that determines instruction behavior, similar to the WAM but adapted for reader/writer semantics. When unification encounters an unbound reader, it returns a suspension result rather than failing, triggering goal suspension until the paired writer receives a value.

### Data Structures

#### Goal State
Each goal maintains its execution context as a Dart class:

```dart
class GoalState {
  final int goalId;
  final Uint8List bytecode;
  int programCounter;
  List<Cell> argumentRegisters;
  List<Cell> temporaryRegisters;
  Environment? environment;
  int continuationPointer;
  SuspensionSet? suspensionSet;
  GoalStatus status; // Active, Suspended, Failed
  int tailRecursionBudget = 26; // Number of consecutive tail calls allowed
}
```

#### Heap Cell Representation
Heap cells use Dart's type system with tagged unions:

```dart
abstract class Cell {
  CellTag get tag;
}

class WriterCell extends Cell {
  Cell? binding;
  final int variableId;
  bool isUnbound() => binding == null;
}

class ReaderCell extends Cell {
  final WriterCell pairedWriter;
  bool isReady() => !pairedWriter.isUnbound();
}

class StructureCell extends Cell {
  final String functor;
  final int arity;
  final int heapAddress;
}

class ConstantCell extends Cell {
  final dynamic value; // atom, integer, string, etc.
}
```

#### Environment Frame
Stack frames for permanent variables:

```dart
class Environment {
  final Environment? parent;
  final int continuationPointer;
  final List<Cell> permanentVariables;
  
  Environment(this.parent, this.continuationPointer, int size) 
    : permanentVariables = List.filled(size, WriterCell.unbound());
}
```

#### Variable Table
Tracks shared variables for SRSW enforcement:

```dart
class VariableEntry {
  final int variableId;
  final WriterCell writer;
  ReaderCell? reader;
  final Set<int> suspendedGoals;
  bool abandoned = false;
  
  void suspend(int goalId) {
    suspendedGoals.add(goalId);
  }
  
  void reactivate() {
    for (final goalId in suspendedGoals) {
      scheduler.reactivate(goalId);
    }
    suspendedGoals.clear();
  }
}
```

### Execution Pipeline

#### Instruction Fetch and Decode
The runtime fetches instructions from bytecode streams and decodes them into operations. Each instruction handler is a Dart function that operates on the goal state:

```dart
typedef InstructionHandler = ExecutionResult Function(GoalState state);

enum ExecutionResult {
  continue_,
  suspend,
  fail,
  succeed
}
```

The instruction dispatcher uses a jump table indexed by opcode for efficient dispatch. Operands are decoded based on instruction type, with register references, constants, and labels extracted as needed.

#### Goal Reduction Cycle
Each active goal executes in a microtask that runs until it suspends, fails, or completes. The basic execution cycle fetches the instruction at the program counter, decodes and validates operands, executes the instruction handler, and processes the result. On CONTINUE, execution proceeds to the next instruction. On SUSPEND, the goal is moved to the suspension table with its suspension set recorded. On FAIL, backtracking is triggered if choice points exist, otherwise the goal terminates. On SUCCEED, the goal completes successfully and is removed from scheduling.

#### Suspension and Reactivation
When a goal encounters an unbound reader during unification, suspension occurs immediately. The suspension mechanism captures the complete goal state including program counter, registers, and environment. The goal is indexed in the suspension table by all readers in its suspension set. When a writer receives a value through successful unification, the runtime locates all goals suspended on the corresponding reader, removes them from the suspension table, and schedules them as microtasks for re-execution. This reactivation is atomic to prevent race conditions in concurrent execution.

## Instruction Implementation

### Head Processing Instructions

Head instructions perform writer MGU between clause heads and incoming goals. The `head_structure` instruction first dereferences its argument to handle variable chains. If it finds a matching structure, it enters READ mode for traversal. If it finds a writer variable, it enters WRITE mode to build the structure. If it finds a reader variable, it suspends the goal. The subsequent `head_writer` and `head_reader` instructions operate based on the current mode, either extracting values in READ mode or creating new variables in WRITE mode.

### Body Construction Instructions  

Body instructions prepare arguments for goal calls. The `put_structure` instruction allocates heap space and initializes structure headers. The `put_writer` and `put_reader` instructions place variable references in argument registers, with readers creating references to their paired writers. These instructions never suspend as they only prepare data rather than performing unification.

### Control Flow Implementation

The `spawn` instruction creates a new process in Dart's microtask queue for executing a procedure. For all body goals except the final one, this instruction ensures fair scheduling by placing the new process at the tail of the queue. This prevents any single recursive predicate from monopolizing execution time while allowing concurrent goals to make progress.

The `requeue` instruction implements tail recursion optimization with bounded iterations. It reuses the current process frame and decrements a tail-recursion budget counter. When the counter is positive, the process is rescheduled as a microtask, maintaining GLP-internal fairness. When the counter reaches zero, it resets and the process is scheduled via the event queue using `Timer.run()`, ensuring system-level responsiveness. This mirrors FCP's reduction-counting mechanism, preventing tail-recursive computations from starving other system events while avoiding unbounded process queue growth.

The `proceed` instruction completes the current procedure and returns control to the continuation point saved by the previous `spawn` instruction. This allows the spawning process to continue with its next instruction after the spawned goal completes.

### Suspension Management

The `suspend` instruction is typically not explicit in bytecode but triggered by unification failure on readers. When suspension occurs, the runtime captures the goal's complete state and indexes it by suspension variables. The `reactivate` instruction (usually implicit when writers are bound) locates suspended goals and reschedules them. The `abandon` instruction marks variables as permanently unbound, causing suspended goals to fail when reactivated.

## Integration with Dart

### Memory Management
The runtime relies entirely on Dart's garbage collector, eliminating the complex memory management in FCP. Heap cells are regular Dart objects subject to standard collection. Environment frames are collected when no longer referenced by active goals. The variable table uses weak references to allow collection of abandoned variables. No explicit memory barriers or generation tracking is needed as in FCP.

### Concurrency Model
Each goal runs as a Dart microtask, providing cooperative concurrency without preemption. The runtime implements two levels of fairness:

1. **Fairness among GLP goals**: Both `spawn` and `requeue` add goals at the tail of the microtask queue, ensuring FIFO scheduling between concurrent GLP goals.

2. **System responsiveness**: To avoid starving event-queue tasks (timers, I/O, UI), goals track a tail-recursion budget. After a fixed number of consecutive `requeue` operations (e.g., 26), the goal yields to the event queue via `Timer.run()` instead of `scheduleMicrotask()`, then continues. This bounded tail-recursion mirrors FCP's reduction-counting mechanism.

I/O operations use Dart's async/await, suspending the goal naturally. This model is simpler than FCP's explicit process queue while maintaining both fairness and responsiveness.

### Native Integration
System predicates are implemented as Dart functions registered with the runtime. These can access Dart libraries directly for functionality like file I/O, networking, and GUI operations. Guards are special system predicates that return success/failure without side effects. The runtime provides a foreign function interface (FFI) for calling native code when necessary.

## Optimizations

### Instruction Fusion
Common instruction sequences are detected and fused into single operations. For example, `head_structure` followed by `head_writer` for the first argument can be combined into `head_structure_writer`. This reduces instruction dispatch overhead and improves cache locality.

### Register Allocation
The compiler performs register allocation to minimize register spilling. Temporary variables that don't cross procedure calls use X registers. Variables with non-overlapping lifetimes share registers. The first few arguments are passed in registers, with remaining arguments using the stack.

### Suspension Optimization
The suspension table uses efficient indexing structures to quickly locate goals suspended on specific variables. Batch reactivation processes all goals suspended on a variable in a single scheduler operation. Early abandonment detection prevents unnecessary suspension by detecting permanently unbound variables during compilation where possible.

## Error Handling

### Runtime Errors
The runtime detects and reports several categories of errors. SRSW violations occur when multiple writers or readers are created for the same variable. Type errors arise when operations receive unexpected argument types. Stack overflow is detected when the logical stack exceeds limits. Abandoned variable access happens when attempting to use variables whose writers are gone.

### Debugging Support
The runtime provides comprehensive debugging facilities. Execution tracing shows instruction-by-instruction execution with register and heap state. Breakpoints can be set on specific predicates or instructions. The suspension inspector shows currently suspended goals and their suspension sets. Variable tracking follows the lifecycle of specific variables through creation, binding, and abandonment.

## Performance Characteristics

### Time Complexity
Instruction dispatch is O(1) using jump tables. Writer MGU is O(n) in structure size without deep recursion. Suspension table operations are O(log n) using balanced trees. Reactivation is O(k) for k suspended goals on a variable.

### Space Complexity  
Each goal requires O(1) base overhead plus O(v) for v permanent variables. Heap growth is O(t) for t total terms created. The suspension table is O(s) for s suspended goals. No trail stack is needed due to the absence of backtracking in concurrent execution.

### Comparison with FCP
This runtime is simpler than FCP's abstract machine by delegating to Dart for memory management, process scheduling, and garbage collection. Performance is comparable for most workloads, with overhead from Dart's abstractions offset by elimination of manual memory management. The design prioritizes maintainability and integration with the Dart ecosystem over maximum theoretical performance.

## Implementation Roadmap

### Phase 1: Core Runtime
Implement the basic execution engine with the instruction set, heap and environment management, and writer MGU algorithm. This provides a working GLP system for single-agent programs.

### Phase 2: Suspension System  
Add suspension table management, reactivation mechanisms, and abandonment detection. This enables concurrent GLP programs with reader/writer synchronization.

### Phase 3: Optimizations
Implement instruction fusion, register allocation improvements, and tail call optimization. These optimizations improve performance for production workloads.

### Phase 4: Debugging Tools
Add execution tracing, breakpoint support, and suspension inspection. These tools are essential for GLP program development.

### Phase 5: Multiagent Extension
Extend to multiple isolates for true multiagent execution, adding inter-isolate message passing and distributed variable management. This completes the full GLP vision for grassroots platforms.

## Conclusion

This runtime system specification provides a practical path to implementing GLP on the Dart platform. By leveraging Dart's built-in capabilities rather than reimplementing low-level functionality, the design achieves simplicity without sacrificing the unique features that make GLP suitable for grassroots platform development. The clear separation between GLP-specific logic and platform services enables portability while maintaining efficient execution on modern devices.