\documentclass[runningheads,thm-restate]{llncs}

% Essential packages for LNCS
\usepackage{graphicx}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{xcolor}
\usepackage{enumitem}

% Algorithm packages
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

% Your specific packages
\usepackage{multirow}
\usepackage{mathtools}
\usepackage{relsize}
\usepackage{bm}
\usepackage{verbatimbox}
\usepackage{wrapfig}
\usepackage{thmtools}

% Your custom formatting commands
\newcommand{\mypara}[1]{\smallskip\noindent\textbf{#1.}}
\newcommand{\temph}[1]{\textbf{#1}}  % or use \emph{#1}
\newcommand{\remove}[1]{}
\newcommand{\udi}[1]{\textcolor{blue}{[Udi says: #1]}}
\newcommand{\claude}[1]{\textcolor{red}{[Claude: #1]}}

% Your abbreviation commands
\newcommand{\glp}{\textsc{GLP}\xspace}
\newcommand{\lp}{logic programs\xspace}
\newcommand{\cp}{Concurrent Prolog\xspace}
\newcommand{\scl}{\textsc{scl}\xspace}
\newcommand{\gsn}{\textsc{gsn}\xspace}

% Your math commands
\newcommand{\calV}{\mathcal{V}}
\newcommand{\calG}{\mathcal{G}}
\newcommand{\calT}{\mathcal{T}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\calR}{\mathbb{R}}
\newcommand{\calN}{\mathbb{N}}
\newcommand{\calA}{\mathcal{A}}
\newcommand{\V}{\mathcal{V}}
\newcommand{\calS}{\mathcal{S}}
\newcommand{\calL}{\mathcal{L}}
\newcommand{\calP}{\mathcal{P}}
\newcommand{\calM}{\mathcal{M}}
\newcommand{\calE}{\mathcal{E}}
\newcommand{\calB}{\mathcal{B}}
\newcommand{\calC}{\mathcal{C}}
\newcommand{\calX}{\mathcal{X}}
\newcommand{\calD}{\mathcal{D}}

% Roman numeral abbreviations
\newcommand{\ia}{\textit{i}}
\newcommand{\ib}{\textit{ii}}
\newcommand{\ic}{\textit{iii}}
\newcommand{\id}{\textit{iv}}
\newcommand{\iie}{\textit{v}}
\newcommand{\iif}{\textit{vi}}
\newcommand{\iiv}{\textit{iv}}
\newcommand{\iv}{\textit{v}}

% Program counter for examples
\newcounter{pc}
\newcommand\spc{\addtocounter{pc}{1}\thepc}
\newcommand{\Program}[1]{\medskip\noindent\textbf{Program \spc: #1}\vspace{-5pt}}

% Set list spacing
\setlist{nosep, leftmargin=*}
\setlist{itemsep=1pt, topsep=3pt, leftmargin=*}

\newtheorem{observation}{Observation}
\raggedbottom  % Prevents vertical justification

% Bibliography style
\bibliographystyle{plain}

\begin{document}

\title{\smaller GLP $\mapsto$ Dart:  Specification, Programming Environment, Examples, and Implementation}
\titlerunning{GLP \rightarrow Dart}
\author{Ehud Shapiro}
\authorrunning{Shapiro}
\institute{London School of Economics and Weizmann Institute of Science}

\maketitle

\begin{abstract}
Grassroots platforms are distributed applications run by\linebreak  cryptographically-identified people on their networked personal devices, where multiple disjoint platform instances emerge independently and coalesce when they interoperate. Their foundation is the grassroots social graph, upon which grassroots social networks, grassroots cryptocurrencies, and grassroots democratic federations can be built.

Grassroots Logic Programs (GLP) was presented as a secure, multiagent, concurrent, logic programming language for implementing grassroots platforms. GLP extends logic programs with paired single-reader/single-writer (SRSW) logic variables, providing secure communication channels among cryptographically-identified people through encrypted, signed and attested messages, which enable identity and code integrity verification.  
Here, we describe a workstation-based implementation of concurrent GLP in Dart.  It is a stepping-stone towards smartphone-based, secure, multiagent, implementation of GLP, as well as valuable on its own right as a powerful GLP program development environment.

We recall logic programs and  concurrent GLP, present programming examples,  notably metaprogramming-based GLP development tools, and describe the GLP Virtual Machine, instruction set, and compiler.

The work was carried out with the intensive help of AI (mainly Claude).  The presence of a formal operational semantics for the language proved an immense asset throughout the development process: Initially, it served as the guiding light for specifying the Virtual Machine and instructions set.  Latter, during development, it was used to resolve any ambiguities and misunderstanding AI had regarding the verbal descriptions of the VM and instruction set and facilitated their ongoing refinement.  While I was hand-holding AI and guiding its development process, the ``authority'' was not me but the formal spec of GLP, which, surprisingly, has not changed during the entire process.
\end{abstract}

\section{Introduction}
\mypara{Grassroots platforms} Grassroots platforms~\cite{shapiro2023grassrootsBA} are distributed applications in which multiple disjoint platform instances emerge independently and coalesce when they interoperate. They are run by people on their networked personal devices (today—smartphones), who are identified cryptographically~\cite{rivest1978method}, communicate only with authenticated friends, and can participate in multiple instances of multiple grassroots platforms simultaneously. The grassroots social graph~\cite{shapiro2023gsn} is both a platform in its own right and the infrastructure layer for all other grassroots platforms. In it, nodes represent people, edges—authenticated friendships, and connected components arise spontaneously and interconnect through befriending. The social graph provides grassroots platforms with communication along graph edges, encrypted for ensuring privacy, signed for authenticity and attested for integrity. Upon this foundation, grassroots social networks~\cite{shapiro2023gsn}, grassroots cryptocurrencies~\cite{shapiro2024gc}, and grassroots democratic federations~\cite{shapiro2025GF} are built.


\mypara{Programming grassroots platforms}  A key challenge in implementing grassroots platforms is overcoming faulty and malicious participants~\cite{lamport1982byzantine}. Without secure language support, correct participants cannot reliably identify each other, establish secure communication channels, or verify each other's code integrity~\cite{sabt2015trusted,costan2016intel}. 
While grassroots platforms have been formally specified and their properties  proven~\cite{shapiro2023grassrootsBA,shapiro2023gsn,shapiro2024gc,shapiro2025GF,shapiro2025atomic}, they are so far mathematical constructions without an actual implementation. To the best of our knowledge, no existing programming language provides the necessary combination of distributed execution, cryptographic security, safety, and liveness guarantees required to realize these specifications. Grassroots Logic Programs aim to close the gap between the mathematical specifications and actual implementation of grassroots platforms.



\mypara{Grassroots Logic Programs}  Grassroots Logic Programs (GLP), a secure, multiagent, concurrent, logic programming language designed for implementing grassroots platforms~\cite{shapiro2025glp}. 
GLP extends logic programs~\cite{lloyd1987foundations,sterling1994art} with paired single-reader/single-writer variables (akin to futures and promises~\cite{dauth2019futures,azadbakht2020formal}), each establishing a secure single-message communication channel between the single writer and the single reader, enabling subsequent secure multidirectional communication by sharing readers and writers in messages.

Through signed attestations at the language level, participants verify each other's identity and code integrity when befriending and communicating. These mechanisms enable both cold calls (for bootstrap and connecting disconnected components) and friend-mediated introductions (the preferred trust propagation method).

\mypara{Concurrent GLP:} Here, we focus on Concurrent GLP a subset of GLP that does not address multiagents or security.  Concurrent GLP  extends logic programs with reader/writer pairs satisfying  the Single-Reader/Single-Writer requirement and extends unification to suspend upon an attempt to bind a reader.  We recall the nondeterministic transition system-based operational semantics of GLP from~\cite{shapiro2025glp}, and provide GLP with deterministic `workstation implementation-ready' transition system, based on which the workstation implementation of GLP is  developed.
sage-passing using dynamic shared-variable tables, geared for smartphone deployment.


The remainder of this paper is organized as follows. Section~\ref{section:lp} recalls logic programs. Section~\ref{section:glp} extends them to concurrent GLP. Section~\ref{section:programming-examples} presents  GLP programming techniques, notably metaprogramming for program development and runtime control.
Section~\ref{section:implementation} presents  a deterministic transition system for GLP, a GLP Virtual Machine, its instruction set, and compiler.
Section~\ref{section:implementation-status} provides the current implementation status and development roadmap.
Section \ref{section:conclusion} concludes.
The appendixes provide a full specification of the VM and instruction set, complete bytecode instruction reference, runtime architecture, and compiler design specification.

\section{Logic Programs}\label{section:lp}

Here we introduce transition systems, providing the formal framework for the operational semantics of both Logic Programs and Grassroots Logic Programs.
We recall standard Logic Programs (LP): syntax, most-general unifier (mgu), operational semantics via nondeterministic goal/clause reduction, compositional semantics. 

\subsection{Transition Systems}


We use $\subset$ to denote the strict subset relation, $\subseteq$ when equality is also possible, and $a\ne b \in S$ as a shorthand for $a\ne b\wedge a\in S \wedge b\in S$.
%
The following definition uses `configuration' rather than the more standard `state'  to avoid confusion with the `local state' of agents in a multiagent transition system, Definition~\ref{definition:mts}.

\begin{definition}[Transition System]\label{definition:ts}
A \temph{transition system} is a tuple $TS = (C, c0, T)$ where:
\begin{itemize}
    \item $C$ is an arbitrary set of \temph{configurations}
    \item $c0 \in C$ is a designated \temph{initial configuration}
    \item $T \subseteq C \times C$ is a \temph{transition relation}. A transition $(c,c') \in T$ is also written as $c \rightarrow c' \in T$.
\end{itemize}
A transition $c \rightarrow c' \in T$ is \temph{enabled} from configuration $c$. A configuration $c$ is \temph{terminal} if no transitions are enabled from $c$. A \temph{computation} is a (finite or infinite) sequence of configurations where for each two consecutive configurations $(c,c')$ in the sequence, $c \rightarrow c' \in T$. A \temph{run} is a computation starting from $c0$, which is \temph{complete} if it is infinite or ends in a terminal configuration.
\end{definition}


\subsection{Logic Programs Syntax}

The syntax of Logic Programs follows the standard in logic programming and Prolog, and is formally defined in Appendix~\ref{appendix:lp}. We note that $V$ denotes the set of all variables and $\calT$ the set of all terms.
We recall the quintessential logic program for list concatenation as an example:
\begin{example}[Append]
\begin{verbatim}
append([X|Xs], Ys, [X|Zs]) :- append(Xs, Ys, Zs).
append([], Ys, Ys).
\end{verbatim}
Logically, a logic program clause $A$\verb|:-| $B$ is a universally-quantified implication in which $B$ implies $A$, and a program is a conjunction of its clauses.
By convention, we use plural variable names like \verb|Xs| to denote a list of \verb|X|'s, 
\end{example}

\subsection{Logic Programs Operational Semantics}

\begin{definition}[Substitution, Instance, Unifier, Most-General Unifier]\label{definition:substitution}
A \temph{substitution} $\sigma$ is an idempotent function $\sigma: V \xrightarrow{} \calT$, namely a mapping from variables to terms applied to a fixed point. By convention, $\sigma(x)=x\sigma$.
\begin{itemize}
    \item Given a substitution $\sigma$, $V_\sigma := \{ X \in V ~|~ X\sigma \ne X\}$.
    \item Given a term $T \in \calT$ and a substitution $\sigma$,  $T\sigma$ is the term obtained from $T$ by replacing every variable $X \in T$ by the term $X\sigma$.
    \item The partial order on terms $\preceq \subset \calT \times \calT$ is defined by $T \preceq T'$, or $T'$ is an \temph{instance} of $T$, if there is a substitution $\sigma$ for which $T\sigma = T'$.
    If $T \ne T\sigma$ we say that $\sigma$ \temph{instantiates} $T$. 
   
    \item For substitutions $\sigma$ and $\sigma'$, $\sigma \preceq \sigma'$ if for every $T \in \calT$, $T\sigma \preceq T\sigma'$, $\sigma$ is \temph{as general as}  $\sigma'$ if $\sigma \preceq \sigma'$.
    \item A substitution $\sigma$ is a \temph{unifier} of two terms $T, T' \in \calT$ if $T\sigma = T'\sigma$; it is a \temph{most-general unifier (mgu)} of $T, T'$ if in addition it is as general as any other unifier of $T$ and $T'$.
\end{itemize}
\end{definition}

Namely, a most general unifier is frugal in not instantiating variables more than necessary.

\begin{remark}[Substitution as Assignment Set]
We  view a substitution $\sigma$ equivalently as a set of assignments $\{X_1:=T_1, \ldots, X_n:=T_n\}$ where $X_i\sigma = T_i$ and $T_i=T_i\sigma=T$. Thus the singleton substitution mapping $X$ to $T$ is $\{X:=T\}$, its application $T\sigma$ may be written $T\{X:=T\}$, the empty substitution is $\emptyset$, and composition of commutative substitutions corresponds to set union.
\end{remark}

\begin{definition}[Renaming, Rename apart]\label{definition:renaming}
A \temph{renaming} is a substitution $\sigma: V \mapsto V$ that maps variables to variables.
A renaming $\sigma$ renames $T'$ \temph{apart from} $T$ if $T'\sigma$ and $T$  have no variable in common.
\end{definition}
We assume a fixed renaming-apart function, so that the result of renaming $T'$ apart from $T$ is well defined.
Next we define the operational semantics of Logic Programs via a transition system.
 
\begin{definition}[LP Goal/Clause Reduction]\label{definition:logic-goal-clause-reduction}
Given LP goal $A$ and clause $C$,  with $H \verb|:-| B$ being the result of renaming $C$ apart from $A$, the \temph{LP reduction} of $A$ with $C$ \temph{succeeds with result} $(B,\sigma)$ if $A$ and $H$ have an mgu $\sigma$,  else \temph{fails}.
\end{definition}

\begin{definition}[Logic Programs Transition System]\label{definition:lp-ts}
A transition system $LP = (C,c0, T)$ is a \temph{Logic Programs transition system} for a logic program $M$ and initial goal $G_0 \in \mathcal{G}(M)$ if 
$C=\mathcal{G}(M)$, $c0=G_0$, and $T$
is the set of all transitions $G \rightarrow G' \in \mathcal{G}(M)^2$ such that for some atom $A \in G$ and clause $C \in M$  the LP reduction of $A$ with $C$ succeeds with result $(B,\sigma)$, and $G' = (G \setminus \{A\} \cup B)\sigma$.
\end{definition}
We write $G \xrightarrow{\sigma} G'$ when we want to make the substitution of a reduction explicit.
As a tribute to resolution theorem proving~\cite{robinson1965machine}—the intellectual ancestor of logic programming—a configuration of $LP$ is also referred to as a \emph{resolvent}.

Logic Programs have two forms of nondeterminism: the choice of $A\in G$, called \emph{and-nondeterminism}, and then choice of  $C\in M$, called \emph{or-nondeterminism}.  Thus, as an abstract model of computation, LP  are  closely-related to \emph{Alternating Turing Machines}, a generalization of Nondeterministic Turing Machines~\cite{shapiro1984alternation}.

\begin{definition}[Proper Run and Outcome]\label{definition:proper-run}
A run $\rho: G_0 \xrightarrow{\sigma_1} G_1 \xrightarrow{\sigma_2} \cdots \xrightarrow{\sigma_n} G_n$ of $LP$ is \temph{proper} if for any $1\le i<  n$,  a variable that occurs in  $G_{i+1}$ but not in  $G_i$ also does not occur in any $G_j$, $j<i$.   If proper, the \temph{outcome} of $\rho$ is $(G_0 \verb|:-| G_n)\sigma$ where $\sigma = \sigma_1 \circ \sigma_2 \circ \cdots \circ \sigma_n$.
\end{definition}
It so happens that the set of all outcomes of all proper runs of a logic program constitutes its fully-abstract compositional semantics~\cite{gaifman1989fully}.
Next we prove the key safety property of LP:

\begin{restatable}[LP Computation is Deduction]{proposition}{LPComputationisDeduction}\label{proposition:LP-computation-deduction}
The outcome\linebreak $(G_0$ :- $G_n)\sigma$ 
of a proper run $\rho: G_0 \xrightarrow{\sigma_1} G_1 \xrightarrow{\sigma_2} \cdots \xrightarrow{\sigma_n} G_n$ of $LP$, where $\sigma = \sigma_1 \circ \sigma_2 \circ \cdots \circ \sigma_n$,  is a logical consequence of $M$.
\end{restatable}

\section{Grassroots Logic Programs}\label{section:glp}

We present Grassroots Logic Programs (GLP) as an extension of Logic Programs: The syntax is extended with reader variables $X?$, where $X$ and $X?$ form a reader/writer pair, and with the Single-Reader/Single-Writer syntactic restriction on clauses.  For example, here is the quintessential concurrent logic program for merging two streams (incrementally constructed, potentially unbounded lists), written in GLP.  Its first two arguments are the input streams to be merged,  the third is the merged output stream:

\Program{GLP Fair Stream Merger}\label{program:merge}
\begin{small}
\begin{verbatim}
merge([X|Xs],Ys,[X?|Zs?]) :- merge(Ys?,Xs?,Zs). % output from first stream
merge(Xs,[Y|Ys],[Y?|Zs?]) :- merge(Xs?,Ys?,Zs). % output from second stream
merge([],[],[]).                                % terminate on empty streams
\end{verbatim}
\end{small}
Note that in each clause, each reader or writer occurs at most once.

The operational semantics of GLP extends that of LP as follows:
\begin{enumerate}
\item \textbf{Synchronisation}: Unification may only instantiate writers, so in addition to succeed/fail, unification may suspend if it requires instantiating readers.

\item \textbf{Communication}: When a unifying writer substitution binds a writer $X$ to a term $T$, the message  $X? := T$ encoding its paired reader assignment is created and added to the configuration. Its application happens asynchronously, realizing a message $T$ from the single occurrence of $X$ to the single occurrence of $X?$. 

\item \textbf{Deterministic clause selection}: The first applicable clause is chosen, not nondeterministically as in LP. This provides for the fairness of \verb|merge| presented above:  As long as the two input streams are available the output dovetails the two inputs, due to switching their order in the recursive call of the first clause; as long as only one stream is available, its elements are copied to the output; and when both streams are unavailable the goal suspends.
\end{enumerate}

The remainder of this section presents GLP syntax, nondeterministic operational semantics, and safety properties. A deterministic `workstation implementation-ready' transition-system specification for GLP is presented in Appendix~\ref{appendix:irGLP}. 

\subsection{GLP Syntax}

\mypara{Reader/Writer pairs}
GLP extends Logic Programs with paired reader/writer variables, where a \emph{writer} $X$ is a single-assignment variable (promise) and its \emph{paired reader $X?$} provides read-only access to the (future) value of $X$. We denote by $V$ the set of all writers, $V?$ the set of all readers and, $\mathcal{V} = V \cup V?$ the set of all variables, where for each writer $X \in V$ there exists a paired reader $X? \in V?$.  
We view $?$ as an identity suffix operator on non-writers, namely  $(X?)?=X?$ for $X?\in V?$ and $T?=T$ for $T\notin \calV$. 
We use $\calA_?$ and $\calG_?$ to denote the set of all atoms and goals, respectively, over $\calV$ (i.e., goals that may contain both readers and writers), and for a GLP program $M$,  $\calA_?(M)$  and $\calG_?(M)$ to denote the subsets of  $\calA_?$ and $\calG_?$, respectively,  restricted to the vocabulary of $M$.



\mypara{Single-Reader/Single Writer (SRSW)} The fundamental requirement in GLP is \emph{single-writer}: any writer may occur at most once in any state of a computation, ensuring there can be no conflict when writing on a logic variable. We extend it to the \emph{single-reader/single-writer (SRSW) requirement} that any reader also occurs at most once. The reason is that with multiple instances of a reader, instantiating the writer to a term containing another writer would give all instances of the paired reader access to that writer, violating the single-writer requirement.  
The SRSW requirement is realized by two complementary concepts:
\begin{enumerate}
    \item \emph{SRSW syntactic restriction on clauses}: Variables in a clause occur as reader/writer pairs, with exactly one of each. 
    \item \emph{SRSW invariant}:  Given a resolvent that satisfies the SRSW requirement, applying to it a goal reduction with a clause that satisfies the SRSW syntactic restriction produces a new resolvent that also satisfies the SRSW requirement.
\end{enumerate}
This SRSW syntactic restriction excludes programs like the equality definition $X=X$ as it has two occurrences of the writer $X$. At the same time it
eliminates the need for distributed atomic unification~\cite{kleinman1990distributed}—replacing it with efficient point-to-point communication of a single assignment from the single occurrence of a writer to the single occurrence of its paired reader.

\mypara{No writer-to-writer binding (WxW)}
In addition, GLP requires \emph{no writer-to-writer} binding (WxW).  A reader/writer pair $X?/X$ is a communication channel from the writer $X$ to the reader $X?$.
It two writers $X$ and $Y$ are unified during execution, the SRSW requirement implies that no occurrences of either $X$ or $Y$ are left to instantiate them, and therefore their paired readers $X?$ and $Y?$ will be left \emph{abandoned}.  Combined,  the WxW and SRSW restrictions ensure that communication channels are properly closed, with no reader is left abandoned by their paired variable.\footnote{We discuss below a relaxation, allowing a reader to abandon its paired writer using anonymous variables $_$, which useful in case there is no need to read the channel any more.}



\subsection{GLP Operational semantics}

\begin{definition}[Writer and Reader Substitution, Reader Counterpart, Suspension Set, Writer MGU]\label{definition:glp-unification}

A substitution $\sigma$ is a \temph{writer substitution} if  $\sigma$: 
\begin{enumerate}
    \item only binds writers: $V_\sigma \subset V$
    \item does not bind writers to writers: if $X\ne X\sigma$ for $X\in V$ then $X\sigma\notin V$
    \item does not form cycles through readers:  $X?$ does not occur in $X\sigma$ for any $X \in V_\sigma$
\end{enumerate}
A substitution $\sigma$ is a \temph{reader substitution} if $V_\sigma \subset V?$.
If $\sigma$ is a writer substitution then its \temph{reader counterpart} is the reader substitution  $\sigma?$  defined by $X?\sigma? = X\sigma$ for every $X\in V_\sigma$.

The \temph{suspension set} of a (regular) substitution $\sigma$ is $W_\sigma:= \{X?\in V? : X?\sigma \notin \calV\}$.

The \temph{writer unification} of two terms:
\begin{enumerate}
    \item \temph{succeeds with $\sigma$} if they have a writer mgu $\sigma$.
    \item else \temph{suspends on $W_\sigma$} if they have a (regular) mgu $\sigma$
    \item else \temph{fails}
\end{enumerate}
\end{definition}
\begin{remark}
If a writer mgu exists it is unique, rather than unique up to renaming,  since it does not include writer-to-writer assignments.
If writer-to-writer assignments were allowed then, by the single-writer restriction, the assignment would leave their two paired readers \emph{abandoned}, namely without a writer that can provide them with a value.   
The occurs check condition for the reader counterpart ensures that no writer is bound to a term containing its paired reader, preventing the formation of circular terms, as proven in Proposition~\ref{proposition:acyclicity}.
\end{remark}

Renaming  (Definition~\ref{definition:renaming}) is extended to respect variable pairing:
\begin{definition}[GLP Renaming]\label{definition:glp-renaming}
 Two GLP terms $T, T'$ have a variable in common if for some writer $X\in V$, either $X$ or $X?$ occur in $T$ and either $X$ or $X?$ occur in $T'$. A \temph{GLP renaming} is a renaming substitution $\sigma: \mathcal{V} \mapsto \mathcal{V}$ such that for each $X\in V$: $X\sigma \in V$ and $X?\sigma = (X\sigma)?$.
\end{definition}

\begin{definition}[GLP Goal/Clause Reduction]\label{definition:glp-goal-clause-reduction}
 Given GLP goal $A$ and clause $C$,  with $H \verb|:-| B$ being the result of the GLP renaming of $C$ apart from $A$,
 the \temph{GLP reduction} of $A$ with $C$ \temph{succeeds with result} $(B,\sigma)$,
\temph{suspends on $W$}, or \temph{fails}, respectively, depending on the result of the writer unification of $A$ and $H$.
\end{definition}

The GLP operational semantics is defined via the following transition system, which employs the notions defined above to extend LP (Definition~\ref{definition:lp-ts}). It abstracts-away goal suspension and failure; these are used in the implementation-ready specifications (Appendixes~\ref{appendix:irGLP} and~\ref{appendix:irmaGLP}) for explicit goal scheduling, suspension and activation.
\begin{definition}[GLP Transition System]\label{definition:glp-ts}
Given a GLP program $M$, an \temph{asynchronous resolvent} over $M$ is a pair $(G,\sigma)$ where $G\in \calG_?(M)$ and $\sigma$ is a reader substitution. 
%
A transition system $GLP = (\calC,c0,\calT)$ is a \temph{GLP transition system} over $M$ and initial goal $G_0 \in \mathcal{G}_?(M)$ satisfying SRSW if:
\begin{enumerate}
    \item $\calC$ is the set of all asynchronous resolvents over $M$
    \item $c0= (G_0,\emptyset)$
    \item $\calT$ is the set of all transitions $(G,\sigma)\rightarrow (G',\sigma')$ satisfying:
    \begin{enumerate}
        \item \textbf{Reduce:} there exists an atom $A \in G$ such that $C \in M$ is the first clause for which the GLP reduction of $A$ with $C$ succeeds with result $(B,\hat\sigma)$,  $G' = (G \setminus \{A\} \cup B)\hat\sigma$, and $\sigma' = \sigma \circ \hat\sigma?$
        \item \textbf{Communicate:} $\hat\sigma = \{X?:=T\} \in \sigma$, $G'= G\hat\sigma$, and $\sigma' = \sigma \setminus \hat\sigma$
\end{enumerate}
\end{enumerate}
\end{definition}
The monotonicity of GLP goal/clause reduction (Proposition~\ref{proposition:glp-monotonicity}) allows a simple \emph{GLP fairness requirement}: A goal that can be reduced is eventually reduced.


\mypara{Guards and system predicates}
GLP also includes \emph{guards}—predicates that test runtime conditions (e.g., \verb|ground(X)| tests if \verb|X| contains no variables) without modifying state, appearing after clause heads separated by \verb=|=—and \emph{system predicates} that provide access to the GLP runtime state and operating system and hardware capabilities (variable state and name, arithmetic evaluation, timestamps). Guards enable conditional clause selection. The \verb|ground(X)| guard allows relaxing the single-reader constraint for \verb|X?| for the clause it occurs in, as having multiple occurrences of \verb|X?| instantiated to a ground term does not violate the fundamental single-writer requirement.
Their specification appears in Appendix~\ref{appendix:guards-system}.

In~\cite{shapiro2025glp} it was shown that, like LP, GLP computations are deductions, but, unlike LP, a goal that can be reduced in a configuration can still be reduced in any subsequent configuration of the computation and additional safety properties.



\subsection{Deterministic Transition System for Concurrent GLP}\label{appendix:irGLP}

This section specifies a workstation (single-agent) implementation-ready transition system for GLP with deterministic execution. 

\begin{definition}[irGLP Configuration]
An \emph{irGLP configuration} over program $M$ is a triple $R = (Q, S, F)$ where:
\begin{itemize}
\item $Q \in \mathcal{A}^*$ is a sequence of active goals
\item $S \subseteq \mathcal{A} \times 2^{V?}$ contains suspended goals with their suspension sets
\item $F \subseteq \mathcal{A}$ contains failed goals
\end{itemize}
\end{definition}

The irGLP reduction extends GLP reduction by activating goals that were suspended on variables instantiated by the reduction, and explicitly failing goals that do not succeed or suspend.

\begin{definition}[irGLP Goal/Queue Reduction]
Given configuration $(Q, S, F)$ with $Q = A\cdot Q'$ and clause $C \in M$, the \emph{irGLP reduction} of $A$ with $C$:
\begin{itemize}
\item \textbf{succeeds with} $(B, \hat\sigma, R)$ if the GLP reduction of $A$ with $C$ succeeds with $(B, \hat\sigma)$ and $R = \{G : (G, W) \in S \wedge X?\in W \wedge X?\hat\sigma? \neq X?\}$
\item \textbf{suspends with} $W_C$ if GLP reduction of $A$ with $C$ suspends on readers $W_C$
\item \textbf{fails} otherwise
\end{itemize}
\end{definition}

\begin{definition}[Implementation-Ready GLP Transition System]
The transition system $\text{irGLP} = (\mathcal{C}, c_0, \mathcal{T})$ over $M$ and initial goal $G_0$ has configurations $\mathcal{C}$ being all irGLP configurations over $M$, with initial configuration $c_0 = (G_0, \emptyset, \emptyset)$, and transitions $\mathcal{T}$ being all transitions $(Q, S, F) \rightarrow (Q', S', F')$ where $Q = A \cdot Q_r$ and:
    \begin{enumerate}
    \item \textbf{Reduce:} If GLP reduction of $A$ with first applicable clause $C \in M$ succeeds with $(B, \hat\sigma,R)$:
        \begin{itemize}
        \item \textbf{Activate:}  $S' = S \setminus \{(G, W) : G \in R\}$,  $F' = F$
        \item \textbf{Schedule:} $Q' = (Q_r \cdot B \cdot R)\hat\sigma\hat\sigma?$
        \end{itemize}
    \item \textbf{Suspend:} Else if $W = \bigcup_{C \in M} W_{C} \neq \emptyset$ then $Q' = Q_r$, $S' = S \cup \{(A, W)\}$, $F' = F$
    \item \textbf{Fail:} Else,  $Q' = Q_r$, $S' = S$, $F' = F \cup \{A\}$.
    \end{enumerate}
\end{definition}

A key restriction compared to the GLP operational semantics is the immediate application of reader substitutions during reduction rather than through asynchronous communication. This simplification is appropriate for workstation execution where all variables are local.


\section{Programming Examples}\label{section:programming-examples}

We present some basic GLP programming techniques through examples. Additional  techniques appear in Appendix~\ref{appendix:additional-techniques}.

\Program{Concurrent Monitor}\label{program:monitor}
\begin{verbatim}
monitor(Reqs) :- monitor(Reqs?,0).

monitor([add(N)|Reqs],Sum) :- 
    Sum1 := Sum? + N?, monitor(Reqs?,Sum1?).
monitor([subtract(N)|Reqs],Sum) :- 
    Sum1 := Sum? - N?, monitor(Reqs?,Sum1?).
monitor([value(V)|Reqs],Sum) :- 
    ground(Sum?) | V = Sum?, monitor(Reqs?,Sum?).
monitor([],_).
\end{verbatim}
An example initial goal is:
\begin{verbatim}
client1(Xs), client2(Ys), merge(Xs?,Ys?,Zs), monitor(Zs?).
\end{verbatim}
The monitor demonstrates a stateful service handling requests from multiple concurrent clients, serialized through stream merging (Program~\ref{program:merge}) whilst maintaining state through the \verb|Sum| parameter in tail-recursive calls. The \verb|value(V)| request demonstrates incomplete messages—upon receipt the monitor binds the response variable \verb|V| to the current sum. 

A fixed number of clients can be served by a fixed binary merge tree.  A dynamically-changing set of clients can be served by the following dynamic stream merger, where an existing client can onboard a new client with a request stream \verb|Ws| by sending down its own request stream the request \verb|merge(Ws?)|, creating a dynamic merge tree as follows.


\Program{Dynamic Stream Merger}\label{program:dynamic-merge}
\begin{verbatim}
merger(Ws,Xs,Out?) :- merge(Ws?,Xs?,Out).

merge([merge(Ws)|Xs],Ys,Zs?) :- 
   merger(Ws?,Xs?,Xs1), merge(Xs1?,Ys?,Zs).
merge(Xs,[merge(Ws)|Ys],Zs?) :- 
   merger(Ws?,Ys?,Ys1), merge(Xs?,Ys1?,Zs).
merge([X|Xs],Ys,[X?|Zs?]) :- 
    X =\= merge(_) | merge(Ys?,Xs?,Zs).
merge(Xs,[Y|Ys],[Y?|Zs?]) :- 
    Y =\= merge(_) | merge(Xs?,Ys?,Zs).
merge([],[],[]).
\end{verbatim}
The resulting merge tree can be highly imbalanced; standard optimization techniques can be applied~\cite{shapiro1984fair,shapiro1986multiway}.

Broadcasting to multiple concurrent consumers uses the \verb|ground| guard to enable input replication without violating the single-writer constraint:

\Program{Concurrent Stream Distribution}\label{program:distribute}
\begin{verbatim}
distribute([X|Xs],[X|Ys1],...,[X|Ysn]) :- 
    ground(X) | distribute(Xs?,Ys1?,...,Ysn?).
distribute([],[],...,[]).
\end{verbatim}
When \verb|X| is ground, multiple occurrences in the clause body do not violate SRSW.
Additional programming examples appear in Appendix~\ref{appendix:additional-techniques}.


\subsection{Blockchain Security of GLP Streams}\label{subsection:blockchain-security}
In~\cite{shapiro2025glp} it was shown that secure multiagent GLP streams achieve blockchain security properties~\cite{nakamoto2008peer,garay2015bitcoin} through language-level guarantees:

\begin{enumerate}
\item \textbf{Immutability:} Once a stream element \verb=[X|Xs]= is created with \verb=X= bound to value \verb=T=, the single-assignment semantics of logic variables prevents any subsequent assignment of \verb=X=. This provides immutability without cryptographic hashing.

\item \textbf{Unforkability:} The SRSW invariant ensures each writer \verb~Xs~ has exactly one occurrence. Attempting to create two continuations \verb~Xs=[Y|Ys]~ and \verb~Xs=[Z|Zs]~ would require two occurrences of writer \verb~Xs~, violating SRSW. This prevents forks at the language level.

\item \textbf{Non-repudiation:} Stream extensions communicated between agents carry attestations $(\verb~Xs:=[Y|Ys]~)_{M,p,q}$. The signature by agent $p$ provides cryptographic proof of authorship that $p$ cannot deny.

\item \textbf{Acyclicity:} Proposition~\ref{proposition:acyclicity} guarantees no circular terms. The occurs check prevents any writer from being bound to a term containing its paired reader, ensuring strict temporal ordering of stream elements.
\end{enumerate}

\mypara{Cooperative Extension} These properties establish that authenticated GLP streams provide blockchain security guarantees through logical foundations rather than proof-of-work or proof-of-stake mechanisms.
Traditional blockchains employ competitive consensus where multiple parties race to extend the chain~\cite{garay2015bitcoin}. GLP's single-writer constraint makes competitive extension impossible---only the agent holding the tail writer can extend a stream. This enables cooperative protocols through explicit handover (Program~\ref{program:cooperative} in Appendix~\ref{appendix:additional-techniques}), supporting round-robin production or priority-based scheduling without consensus overhead.

\mypara{Interlaced Streams are a Blocklace}
When multiple agents maintain interlaced streams that reference each other (Program~\ref{program:interlaced-streams}), they form a blocklace~\cite{almeida2024blocklace}---a DAG where blocks reference multiple predecessors---employed by modern consensus protocols including Cordial Miners~\cite{keidar2023cordial},  Morpheus~\cite{lewis2025morpheus}, and Constitutional Consensus~\cite{keidar2025constitutional}.
The resulting structure provides eventual consistency equivalent to Byzantine fault-tolerant CRDTs~\cite{shapiro2011conflict} while maintaining blockchain integrity guarantees.

In secure multiagent GLP, mutual attestations ensure all participants execute verified code, allowing consensus protocols to handle only network and fail-stop failures rather than Byzantine behaviour, significantly reducing complexity while maintaining safety.



\section{Implementation}\label{section:implementation}

\subsection{Background: Classical Abstract Machines}

\subsubsection{Warren Abstract Machine}

The WAM~\cite{warren1983abstract} compiles Prolog to bytecode executed on a stack-based abstract machine. Key components: (1) Argument registers A1-An pass parameters between predicates; (2) Temporary registers X1-Xn hold intermediate values within clauses; (3) Permanent variables Y1-Yn reside in environment frames for variables spanning multiple goals; (4) The heap stores compound terms as tagged cells; (5) Choice points enable backtracking on failure; (6) The trail records variable bindings for undoing on backtrack.

WAM unification operates through a mode flag (READ/WRITE) that determines whether instructions match existing structures or build new ones. The program counter (P), continuation pointer (CP), and environment pointer (E) manage control flow. Indexing on the first argument accelerates clause selection.

\subsubsection{FCP Abstract Machine}

The FCP abstract machine~\cite{houri1989sequential} implements Flat Concurrent Prolog through process-based execution. Core mechanisms: (1) Process queue holds active goals; (2) Suspension table maps variables to waiting processes; (3) Read-Only Queue (ROQ) manages process activation on variable instantiation; (4) Trail records bindings during guard evaluation for rollback on failure.

Guards execute without side effects. The commit operation atomically applies successful guard bindings. Process fairness is achieved through time-slicing and queue rotation. Unlike Prolog, FCP has no backtracking—failed guards cause clause failure, not search.

\subsection{The GLP Virtual Machine}

\subsubsection{Design Philosophy}

GLP synthesizes WAM's compilation approach with FCP's concurrent execution model. Core design decisions: (1) Reader/writer variable pairs replace Prolog variables; (2) Committed-choice semantics eliminate backtracking; (3) Suspension on unbound readers replaces failure; (4) Two-phase execution separates tentative from committed operations.

\subsubsection{Machine Architecture}

\mypara{Registers}
GLP adopts WAM's register architecture: A1-An for arguments, X1-Xn for temporaries, Y1-Yn for permanent variables. Additional registers: $\kappa$ stores procedure entry point for suspension restart; Mode flag (READ/WRITE) controls structure processing; S points into structure arguments during traversal.

\mypara{Memory Organization}
The heap contains four cell types: (1) WriterCell with optional binding and paired reader reference; (2) ReaderCell referencing its paired writer; (3) StructureCell with functor/arity and argument pointer; (4) ConstantCell for atoms and numbers. No trail needed—single assignment prevents undoing.

\mypara{Goal Management}
Three goal states exist: Active (queued for execution), Suspended (awaiting reader instantiation), Failed (permanently blocked). The ROQ maps readers to suspended goal sets. Goal scheduling uses FIFO ordering with fairness through tail-recursion budgets.

\subsubsection{Two-Phase Execution Model}

\mypara{Phase 1 (HEAD/GUARDS)}
Instructions operate tentatively: (1) Pattern matching collects required bindings in $\hat{\sigma}_w$ without heap mutation; (2) Reader encounters add to suspension set $S_i$; (3) Guards evaluate without side effects; (4) Failure triggers clause\_next to try alternatives.

\mypara{Phase 2 (BODY)}
Post-commit execution: (1) Direct heap mutations permitted; (2) Goal spawning creates new active goals; (3) Environment allocation/deallocation for permanent variables; (4) No failure possible (only suspension).

\subsubsection{Instruction Set Design}

\mypara{Control Instructions}
\texttt{clause\_try}: Initialize $\hat{\sigma}_w = \emptyset$, $S_i = \emptyset$. \texttt{clause\_next L}: Jump to label L on failure/suspension. \texttt{commit}: Apply $\hat{\sigma}_w$ atomically, activate suspended goals. \texttt{suspend}: Create suspension note for readers in U. \texttt{proceed}: Return from deterministic call.

\mypara{Head Instructions}
\texttt{head\_bind\_writer W}: Add W to tentative bindings. \texttt{head\_need\_reader R}: Add R to suspension set. \texttt{head\_structure f/n, Ai}: Process structure tentatively. \texttt{require\_writer\_arg slot}: Verify argument is writer.

\mypara{Body Instructions}
\texttt{body\_set\_const W, c}: Bind writer post-commit. \texttt{put\_structure f/n, Ai}: Build structure. \texttt{allocate n}: Create environment frame. \texttt{call p/n}: Procedure call with continuation. \texttt{spawn p/n}: Create concurrent goal.

\subsubsection{Scheduling and Fairness}

Goal scheduling follows FCP's process model with modifications: (1) FIFO active queue ensures progress; (2) Tail recursion budget (26 iterations) prevents starvation; (3) Suspension on readers enables dataflow synchronization; (4) Wake order preserves FIFO per reader.

\subsection{Comparative Analysis}

\subsubsection{GLP vs WAM}

\mypara{Similarities}
Register architecture (A, X, Y), Heap-based term representation, Compilation to bytecode, Structure processing via S register, Environment frames for permanent variables.

\mypara{Differences}
No choice points or trail (no backtracking). Reader/writer pairs replace logic variables. Suspension replaces failure on unification. Concurrent goal execution vs sequential. No occurs check needed (SRSW prevents cycles).

\subsubsection{GLP vs FCP AM}

\mypara{Similarities}
Process-based concurrency model. Suspension table and ROQ mechanisms. Committed-choice semantics. Guard evaluation without side effects. Fairness through scheduling.

\mypara{Differences}
Bytecode compilation vs direct clause interpretation. Reader/writer pairs enforce single assignment. No distributed unification (SRSW invariant). Tentative bindings ($\hat{\sigma}_w$) vs trail. Phase separation at instruction level.

\subsubsection{Unique Contributions}

GLP's virtual machine introduces: (1) Unified tentative binding mechanism eliminating trail complexity; (2) Language-level SRSW enforcement preventing distributed unification; (3) Two-phase instruction semantics enabling safe concurrent execution; (4) Direct suspension on readers simplifying synchronization.


\section{Implementation Status}\label{section:implementation-status}

\section{Conclusion}\label{section:conclusion}
We have concurrent GLP and described a workstation implementation of it. 


\bibliography{bib}

\appendix

\section{Logic Programs Syntax}\label{appendix:LP-synax}

\begin{definition}[Logic Programs Syntax]\label{definition:lp-syntax}
The syntax of Logic Programs is defined thus:
\begin{itemize}
    \item A \temph{variable} is an alphanumeric string beginning with uppercase letter, e.g. \verb|X, X1, Xs|. We use $V$ to denote the set of all variables.
    
    \item A \temph{constant} is a string beginning with a lowercase letter, e.g. a, a1, and foo, as well as any quoted string, e.g. \verb|","| and \verb|"X"|.
    
    \item A \temph{number} is a numeric string, which may include a decimal point, e.g. 0, 1, 103.65.
    
    \item A \temph{logic term}, or \temph{term} for short is a variable in $V$, a constant, a number, as well as a \temph{composite term} of the form $f(T_1,T_2,\ldots,T_n)$, $n \ge 1$, where $f$ is a constant and each $T_i$ is a term, $i \in [n]$, referred to as a \temph{subterm} of $T$.
    \item A term $T$ \temph{occurs} in term $T'$, denoted $T \in T'$, if $T=T'$ or if $T'$ is an $n$-ary term
    $f(T_1,T_2,\ldots,T_n)$ for some constant $f$ and $T$ occurs in $T_i$ for some $i \in [n]$. A term is \temph{ground} if it contains no variables, namely $X \notin T$ for any $X \in V$. We let $\calT$ denote the set of all terms.

    \item \temph{Lists:} By convention the constant \verb|[]| (read ``nil'') represents an empty list, the binary term \verb=[X|Xs]= represents a (linked) list with the first element \verb|X| and (a link to the) rest \verb|Xs|, the term \verb|[X]| is a shorthand for \verb=[X|[]]= and the term \verb=[X1,X2,...Xn]= is a shorthand for the nested term \verb=[X1|[X2|...[Xn|[]]...]]=. 
    
    \item An \temph{atom} is a constant or a composite term.
    
    \item A \temph{goal} is a term of the form $a_1, a_2,\ldots a_n$, $n\ge 0$, where each $a_i$ is an atom, $i \in [n]$. Such a goal is \temph{empty} if $n=0$, in which case it may also be written as \verb|true|, \temph{atomic} if $n=1$, and \temph{conjunctive} if $n \ge 2$. A conjunctive goal can be written equivalently as $(a_1,(a_2,(\ldots a_n)\ldots))$, where $(a,b)$ is a shorthand for \verb|","|$(a,b)$. As goal order is immaterial here, a conjunctive goal is identified with a multiset of its atoms and an atomic goal with its singleton. Let $\calA$ denote the set of all atoms and $\calG$ the set of all goals.

     \item A \temph{clause} is a term of the form $A$ \verb|:-| $B$ (read `$A$ if $B$'), where $A$ is an atom, referred to as the clause's \temph{head}, and $B$ is a (possibly empty) goal, referred to as the clause's \temph{body}. If $B$ is empty then the clause is called \temph{unit} and can be written simply as $A$. The underscore symbol \verb|_| is a \emph{don't-care variable} that stands for a variable occurring only once, which can be bound to any value that subsequently cannot be unified.
    
    \item A \temph{logic program} is a finite sequences of ``.''-separated clauses.
  As a convention, clauses for the same predicate (name and arity) are grouped together and are referred to as the \temph{procedure} for that predicate.  Given logic program $M$, let $\calA(M)$ and $\mathcal{G}(M)$ be the subsets of $\calA$ and $\calG$, respectively, that include only the vocabulary (constant, function, and predicate symbols) of $M$. 
\end{itemize}
\end{definition}

\section{Social Networking Applications}\label{appendix:social-networking}

Building upon the authenticated social graph, this section demonstrates how GLP enables secure social networking applications. The established friend channels and attestation mechanisms provide verifiable content authorship and provenance guarantees impossible in centralised platforms.

\subsection{Direct Messaging}

Direct messaging establishes dedicated conversation channels between friends, separate from the protocol control channels. When accepting friendship, the acceptor creates a messaging channel and includes it in the acceptance response:

\Program{Direct Messaging Channel Establishment}\label{program:direct-messaging}
\begin{verbatim}
% Modified establishment for direct messaging
% Secure version - verifies DM channel attestation
establish(yes, From, Resp, Fs, Fs1, In, In1) :-
    new_channel(ch(FIn, FOut), FCh),
    new_channel(ch(DMIn, DMOut), DMCh),
    Resp = accept(FCh, DMCh),
    attestation(DMCh, att(From, _)) |  % Verify DM channel from authenticated friend
    handle_friend(From?, FIn?, FOut?, DMIn?, DMOut?, Fs?, Fs1, In?, In1).

handle_friend(From, FIn, FOut, DMIn, DMOut, Fs, 
             [(From, FOut), (dm(From), DMOut)|Fs], In, In1) :-
    tag_stream(From?, FIn?, Tagged),
    merge(In?, Tagged?, In1),
    forward_to_app(dm_channel(From?, DMIn?)).
\end{verbatim}

The protocol maintains separation between control and messaging channels. The friend channel handles protocol messages whilst the direct messaging channel carries conversation data. Each message through the DM channel carries attestation, ensuring non-repudiation and authenticity of the conversation history.

\subsection{Feed Distribution with Verified Authorship}

Content feeds leverage the \verb|ground| guard's relaxation of SRSW constraints to broadcast to multiple followers whilst maintaining cryptographic proof of authorship:

\Program{Authenticated Feed Distribution}\label{program:feed}
\begin{verbatim}
% Post distribution with attestation preservation
post(Content, Followers, Followers1) :-
    ground(Content), current_time(Time) |
    create_post(Content?, Time?, Post),
    broadcast(Post?, Followers?, Followers1).

broadcast(_, [], []).
broadcast(Post, [(Name,Out)|Fs], [(Name,[Post|Out1?])|Fs1]) :-
    broadcast(Post?, Fs?, Fs1).

% Defined guard for attestation preservation  
preserve_attestation(Post, Author, forward(Author?, Post)).

% Forward with attestation verification
forward(Post, Followers, Followers1) :-
    ground(Post), attestation(Post, att(Author, _)),
    preserve_attestation(Post?, Author?, Forward) |
    broadcast(Forward?, Followers?, Followers1).
\end{verbatim}

Each post carries the creator's attestation $(Post)_{M,p,q}$. When forwarding, the original attestation is preserved whilst adding the forwarder's attestation, creating a cryptographically verifiable provenance chain. Recipients can verify both the original author and the complete forwarding path, preventing misattribution and enabling accountability for content distribution.

\subsection{Group Communication}

Groups in GLP follow a founder-administered model where users create groups with selected friends. The founder invites authenticated friends who decide whether to join. Group messages use interlaced streams, creating natural causal ordering without consensus.

\mypara{Group Formation}
Users initiate groups with a name and friend list. The globally unique group identifier is (founder, name), preventing naming conflicts:

\Program{Group Formation Protocol}\label{program:group-formation}
\begin{verbatim}
% User creates group with friend list
social_graph(Id, [msg(user, Id, create_group(Name, Friends))|In], Fs) :-
    create_group_streams([Id|Friends]?, Streams),
    send_invitations(Friends?, Id?, Name?, Streams?, Fs?, Fs1),
    social_graph(Id, In?, [((Id,Name), group(admin, Streams?))|Fs1?]).

% Send invitations through friend channels
send_invitations([], _, _, _, Fs, Fs).
send_invitations([Friend|Friends], Founder, Name, Streams, Fs, Fs1) :-
    lookup(Friend, Fs?, Ch),
    Ch = [inv(Founder?, Name?, Streams?)|Ch1?],
    send_invitations(Friends?, Founder?, Name?, Streams?, [(Friend,Ch1?)|Fs2?], Fs1).

% Receive invitation from friend
social_graph(Id, [msg(From, Id, inv(Founder, Name, Streams))|In], Fs) :-
    attestation(inv(Founder, Name, Streams), att(From, _)) |
    lookup_send(user, msg(agent, user, 
                join_group(From?, Founder?, Name?)), Fs?, Fs1),
    social_graph(Id, In?, Fs1?).

% User decision on invitation
social_graph(Id, [msg(user, Id, join(yes, Founder, Name, Streams))|In], Fs) :-
    social_graph(Id, In?, [((Founder,Name), group(member, Streams?))|Fs?]).
social_graph(Id, [msg(user, Id, join(no, _, _, _))|In], Fs) :-
    social_graph(Id, In?, Fs?).
\end{verbatim}

The founder creates interlaced stream structures for all members and sends invitations through authenticated friend channels. Recipients verify the invitation's attestation before consulting their user. Accepted groups are stored with key (Founder, Name), ensuring uniqueness whilst clarifying ownership.

\mypara{Group Messaging via Interlaced Streams}
Group members maintain independent message streams whilst observing others' messages, creating causal ordering through the interlaced streams mechanism:

\Program{Group Messaging}\label{program:group-messaging}
\begin{verbatim}
% Member participates in group
group_member(Id, (Founder, Name), Streams) :-
    lookup((Founder,Name), Fs?, group(Role, Streams)),
    compose_messages(Id?, Name?, Messages),
    find_my_stream(Id?, Streams?, MyStream),
    interlace(Messages?, MyStream?, [], Streams?).

compose_messages(Id, Name, [Msg|Msgs]) :-
    await_user_input(Id?, Name?, Input),
    format_message(Input?, Id?, Msg),
    compose_messages(Id?, Name?, Msgs?).
compose_messages(_, _, []).

format_message(reply(Text), Id, msg(Id, reply, Text)).
format_message(post(Text), Id, msg(Id, post, Text)).
\end{verbatim}

Members post independently without control tokens. The interlaced streams mechanism (Program~\ref{program:interlaced-streams}) ensures each member's block references all observed messages. When member p replies to message m, the reply appears in p's stream only after p has observed m, creating natural causality where replies follow what they reply to whilst independent messages remain unordered.

Security derives from authenticated friend channels—all group communication occurs through channels established via the social graph protocol, with automatic attestation on every message. Byzantine agents outside the group cannot inject messages as they lack authenticated channels to members. The interlaced structure provides causal consistency equivalent to consensus protocols whilst eliminating their overhead, demonstrating how authenticated channels combined with GLP's concurrent programming primitives enable efficient group communication without centralisation or Byzantine agreement.

\subsection{Content Authenticity and Provenance}

Content authenticity in GLP derives from the attestation mechanism applied recursively through forwarding operations. When agent p creates post P, it carries attestation $(P)_{M,p,*}$. When agent q forwards this post, the forward operation wraps the entire attested post: `forward(p, P)`, which receives attestation $(forward(p,P))_{M,q,*}$. Recipients can verify both q's forwarding attestation and p's original creation attestation, with the nesting depth revealing the complete forwarding chain.

This mechanism addresses three vulnerabilities in conventional social networks. First, impersonation becomes cryptographically impossible—agents cannot forge attestations for other agents' keys. Second, misattribution is prevented—the original author's attestation remains embedded regardless of forwarding depth. Third, conversation manipulation is detectable—group messages through interlaced streams create a tamper-evident partial order where altered histories fail attestation verification. These properties emerge from the language-level integration of attestations with GLP's communication primitives, requiring no external trust infrastructure or consensus protocols.

\section{Guards and System Predicates}\label{appendix:guards-system}

Guards and system predicates extend GLP programs with access to the GLP runtime state, operating system and hardware capabilities.

\mypara{Guard predicates}
Guards provide read-only access to the runtime state of GLP computation. A guard appears after the clause head, separated by \verb=|=, and must be satisfied for the clause to be selected. The following guards are fundamental for concurrent GLP programming:

\begin{itemize}
\item \verb|ground(X)| succeeds if \verb|X| contains no variables. With this guard, the clause body may contain multiple occurrences of \verb|X?| without violating the single-writer requirement, enabling safe replication of ground terms to multiple concurrent consumers.
\item \verb|known(X)| succeeds if \verb|X| is not a variable, though it may not be ground.
\item \verb|writer(X)| and \verb|reader(X)| succeed if  \verb|X| is an uninstantiated writer or reader respectively.  Note that \verb|reader(X)| is non-monotonic.
\item \verb|otherwise| succeeds if all previous clauses for this procedure failed.
\item \verb|X=Y| succeed if $X$ and $Y$ are identical
\item \verb|X=\=Y| succeeds if the unification of $X$ and $Y$ fails. 
\end{itemize}

\mypara{Defined guard predicates}
To support abstract data types and cleaner code organization, GLP provides for user-defined guards, defined unit clauses \verb|p(T1,...,Tn)|.  The call \verb|p(S1,...,Sn)| in the guard is folded to the equalities \verb|T1=S1,...,Tn=Sn| for each unit goal. This mechanism is demonstrated in the channel abstractions below.

\mypara{System predicates}
System predicates execute atomically with goal/clause reduction and provide access to underlying runtime services:
\begin{itemize}
\item \verb|evaluate(Expr?,Result)| evaluates ground arithmetic expressions.
\item \verb|current_time(T)| provides system timestamps for temporal coordination.
\item \verb|variable_name(X,Name)| returns a unique identifier for variable \verb|X| and its pair.
\end{itemize}

\mypara{Arithmetic evaluation in assignments}
Arithmetic expressions are defined by the following clause:
\begin{verbatim}
X? := E :- ground(E) | evaluate(E?,X).
\end{verbatim}
Ensuring the expression is ground before calling the system evaluator, maintaining program safety whilst providing convenient notation for mathematical computations.

\section{Additional Programming Techniques}\label{appendix:additional-techniques}

This appendix presents GLP programs that were referenced in the main text, as well as additional programs that demonstrate the language's capabilities.


\subsection{Channel Abstractions}

Bidirectional channels are fundamental to concurrent communication in GLP. We represent a channel as the term \verb|ch(In?,Out)| where \verb|In?| is the input stream reader and \verb|Out| is the output stream writer. The following predicates encapsulate channel operations and are defined as guard predicates through unit clauses:

\Program{Channel Operations}\label{program:channel-operations}
\begin{verbatim}
send(X,ch(In,[X?|Out?]),ch(In?,Out)).
receive(X?,ch([X|In],Out?),ch(In?,Out)).
new_channel(ch(Xs?,Ys),ch(Ys?,Xs)).
\end{verbatim}

The \verb|send| predicate adds a message to the output stream, \verb|receive| removes a message from the input stream, and \verb|new_channel| creates a pair of channels where each channel's input is paired with the other's output. When used as guards in clause heads, these predicates enable readable code that abstracts the underlying stream mechanics:

\Program{Stream-Channel Relay}\label{program:relay}
\begin{verbatim}
relay(In,Out?,Ch) :- 
    In?=[X|In1], send(X?,Ch?,Ch1) | relay(In1?,Out,Ch1?).
relay(In,Out?,Ch) :- 
    receive(X,Ch?,Ch1), Out=[X?|Out1?] | relay(In?,Out1,Ch1?).
\end{verbatim}

The relay reads from its input stream and sends to the channel in the first clause, while the second clause receives from the channel and writes to the output stream. The channel state threads through the recursive calls, maintaining the bidirectional communication link.

\subsection{Stream Tagging for Source Identification}

When multiple input streams merge into a single stream, the source identity of each message is lost. Stream tagging preserves this information by wrapping each message with its source identifier:

\Program{Stream Tagging}\label{program:tag-stream}
\begin{verbatim}
tag_stream(Name, [M|In], [msg(Name?, M?)|Out]) :-
    tag_stream(Name?, In?, Out?).
tag_stream(_, [], []).
\end{verbatim}

The procedure recursively processes the input stream, wrapping each message \verb|M| in a \verb|msg(Name, M)| term that includes the source name. The tagged stream can then be safely merged with other tagged streams while preserving source information, essential for multiplexed message processing where receivers must determine message origin.

\subsection{Stream Observation}

For non-ground data requiring observation without consumption, the observer technique forwards communication bidirectionally while producing a replicable audit stream:

\Program{Concurrent Observer}\label{program:observer}
\begin{verbatim}
observe(X?, Y, Z) :- observe(Y?, X, Z).
observe(X, X?, X?) :- ground(X) | true.
observe(Xs, [Y1?|Ys1?], [Y2?|Ys2?]) :-
    Xs? = [X|Xs1] |
    observe(X?, Y1, Y2),
    observe(Xs1?, Ys1, Ys2).
\end{verbatim}

\subsection{Cooperative Stream Production}

While the single-writer constraint prevents competitive concurrent updates, GLP enables sophisticated cooperative techniques where multiple producers coordinate through explicit handover:

\Program{Cooperative Producers}\label{program:cooperative}
\begin{verbatim}
producer_a(control(Xs,Next)) :-
    produce_batch_a(Xs,Xs1,Done),
    handover(Done?,Xs1,Next).

producer_b(control(Xs,Next)) :-
    produce_batch_b(Xs,Xs1,Done),
    handover(Done?,Xs1,Next).

handover(done,Xs,control(Xs,Next)).

produce_batch_a([a,b,c|Xs],Xs,done).
produce_batch_b([d,e,f|Xs],Xs,done).
\end{verbatim}

The \verb|control(Xs,Next)| term encapsulates both the stream tail writer and the continuation for transferring control, enabling round-robin production, priority-based handover, or dynamic producer pools.

These examples demonstrate GLP as a powerful concurrent programming language where reader/writer pairs provide natural synchronization, the single-writer constraint ensures race-free concurrent updates, and stream-based communication enables scalable concurrent architectures.

\subsection{Network Switch}

For three agents \verb|p, q ,r| and three channels  with them \verb|Chp, Chq, Chr|, it is initialized with 
\verb|network((p,Chp?),(q,Chq?),(r,Chr?))|.

\Program{3-Way Network Switch}\label{program:3-way-network-switch}
\begin{verbatim}
% P to Q forwarding
network((P,ChP),(Q,ChQ),(R,ChR)) :-
    ground(Q), receive(ChP?,msg(Q,X),ChP1), send(ChQ?,X?,ChQ1) |
    network((P,ChP1?),(Q,ChQ1?),(R,ChR?)).

% P to R forwarding  
network((P,ChP),(Q,ChQ),(R,ChR)) :-
    ground(R), receive(ChP?,msg(R,X),ChP1), send(ChR?,X?,ChR1) |
    network((P,ChP1?),(Q,ChQ?),(R,ChR1?)).

% Q to P forwarding
network((P,ChP),(Q,ChQ),(R,ChR)) :-
    ground(P), receive(ChQ?,msg(P,X),ChQ1), send(ChP?,X?,ChP1) |
    network((P,ChP1?),(Q,ChQ1?),(R,ChR?)).

% Q to R forwarding
network((P,ChP),(Q,ChQ),(R,ChR)) :-
    ground(R), receive(ChQ?,msg(R,X),ChQ1), send(ChR?,X?,ChR1) |
    network((P,ChP?),(Q,ChQ1?),(R,ChR1?)).

% R to P forwarding
network((P,ChP),(Q,ChQ),(R,ChR)) :-
    ground(P), receive(ChR?,msg(P,X),ChR1), send(ChP?,X?,ChP1) |
    network((P,ChP1?),(Q,ChQ?),(R,ChR1?)).

% R to Q forwarding
network((P,ChP),(Q,ChQ),(R,ChR)) :-
    ground(Q), receive(ChR?,msg(Q,X),ChR1), send(ChQ?,X?,ChQ1) |
    network((P,ChP?),(Q,ChQ1?),(R,ChR1?)).
\end{verbatim}

\subsection{Implementation Correctness Properties}

\begin{proposition}[Goal State Integrity]\label{proposition:goal-integrity}
For any configuration $(R_p, V_p, M_p)$ where $R_p = (A_p, S_p, F_p)$ in an IRmaGLP run, every goal of agent $p$ appears in exactly one of $A_p$, $S_p$, or $F_p$. Furthermore, $F_p$ is monotonically increasing: once a goal enters $F_p$, it remains there.
\end{proposition}

\begin{proof}
By induction on transition steps. Initially all goals are in $A_p$. The Reduce transaction (Definition~\ref{definition:IRmaGLP-reduce}) moves goals between sets atomically: from $A_p$ to $S_p$ on suspension, from $S_p$ to $A_p$ on reactivation, and to $F_p$ on failure. No transition removes goals from $F_p$.
\end{proof}

\begin{proposition}[SRSW Preservation in Implementation]\label{proposition:impl-srsw}
If the initial configuration of IRmaGLP satisfies SRSW, then for any reachable configuration and any variable $Y$, at most one agent holds $Y$ locally (in their resolvent) and at most one agent holds $Y'$ locally.
\end{proposition}

\begin{proof}
The variable table $V_p$ tracks all non-local variable references. When agent $p$ exports a variable $Y$ through the export helper (Definition~\ref{definition:IRmaGLP-local-state}), $Y$ is added to $V_p$ marking it as created by $p$ but referenced externally. The Communicate and Network transactions maintain exclusivity by transferring variables between agents rather than duplicating them. The export helper's relay mechanism for requested readers preserves the single-reader property through fresh variable pairs.
\end{proof}

\begin{proposition}[Suspension Correctness]\label{proposition:suspension-correct}
If goal $G$ is suspended on reader set $W$ at agent $p$, then $G$ transitions to active exactly when either: (1) some $X? \in W$ receives a value through a Communicate transaction, or (2) some $X? \in W$ is abandoned.
\end{proposition}

\begin{proof}
The reactivate helper (Definition~\ref{definition:IRmaGLP-local-state}) is called precisely when assignments arrive or abandonment occurs. It removes $(G, W)$ from $S_p$ if $X? \in W$, adding $G$ to the tail of $A_p$. No other operation modifies suspended goals.
\end{proof}

\subsection{Replication of Non-Ground Terms}

While the main text demonstrated distribution of ground terms to multiple consumers, many applications require replicating incrementally-constructed terms that may contain uninstantiated readers. The following replicator procedure handles nested lists and other structured terms, provided the input contains no writers. This technique suspends when encountering readers and resumes as values become available, enabling incremental replication of partially instantiated data structures.

\Program{Non-Ground Term Replicator}\label{program:replicator}
\begin{verbatim}
replicate(X, X?,..., X?) :- 
    ground(X) | true.                          % Ground terms can be shared
replicate(Xs, [Y1?|Ys1?],..., [Yn?|Ysn?]) :-   % List recursion on both parts
    Xs? = [X|Xs1] |
    replicate(X?, Y1,..., Yn),
    replicate(Xs1?, Ys1,..., Ysn).
\end{verbatim}

The replicator operates recursively on list structures, creating multiple copies that maintain the same incremental construction behavior as the original. When the input list head becomes available, all replica heads receive the replicated value simultaneously. This technique extends naturally to tuples through conversion to lists of arguments, enabling replication of arbitrary term structures that contain readers but no writers.

\subsection{Interlaced Streams as Distributed Blocklace}

A blocklace represents a partially-ordered generalization of the blockchain where each block contains references to multiple preceding blocks, forming a directed acyclic graph. This structure maintains the essential properties of blockchains while enabling concurrent block creation without consensus. GLP's concurrent programming model naturally realizes blocklace structures through interlaced streams, where multiple concurrent processes maintain individual streams while observing and referencing each other's progress.

\Program{Interlaced Streams (Blocklace)}\label{program:interlaced-streams}
\begin{verbatim}
% Three agents maintaining interlaced streams
% Initial goal:
%   p(streams(P_stream, [Q_stream?, R_stream?])),
%   q(streams(Q_stream, [P_stream?, R_stream?])),
%   r(streams(R_stream, [P_stream?, Q_stream?]))

streams(MyStream, Others) :-
    produce_payloads(Payloads),
    interlace(Payloads?, MyStream, [], Others?).

interlace([Payload|Payloads], [block(Payload?,Tips?)|Stream?], PrevTips, Others) :-
    collect_new_tips(Others?, Tips, Others1),
    interlace(Payloads?, Stream, Tips?, Others1?).
interlace([], [], _, _).

% Using reader(X) to identify fresh tips not yet incorporated
collect_new_tips([[Block|Bs]|Others], [Block?|Tips?], [Bs?|Others1?]) :-
    reader(Bs) |  % Bs unbound means Block is the current tip
    collect_new_tips(Others?, Tips, Others1).
collect_new_tips([[B|Bs]|Others], Tips?, [[Bs]?|Others1?]) :-
    % Skip B as it's already been referenced
    collect_new_tips([[Bs]?|Others?], Tips, Others1).
collect_new_tips([], [], []).
\end{verbatim}

Each concurrent process maintains its own stream of blocks containing application payloads and references to the most recent blocks observed from other processes. The `reader(X)` guard predicate identifies unprocessed blocks by detecting unbound tail variables, enabling each process to reference exactly those blocks it has not previously incorporated. This creates a distributed acyclic graph structure where the partial ordering reflects the causal relationships between blocks produced by different processes.

The interlaced streams technique demonstrates how GLP's reader/writer synchronization mechanism naturally implements sophisticated distributed data structures. The resulting blocklace provides eventual consistency guarantees similar to CRDTs while maintaining the integrity and non-repudiation properties of blockchain structures. This technique has applications in distributed consensus protocols, collaborative editing systems, and Byzantine fault-tolerant dissemination networks.


\subsection{Metainterpreters}

Program development is essentially a single-agent endeavour:  The programmer trying to write and debug a GLP program.  As in Concurrent Prolog, a key strength of GLP is metainterpretation:  The ability to write GLP interpreters with various functions in GLP.  This allows writing a GLP program development environment and a GLP operating system within GLP itself~\cite{sterling1994art,safra1988meta,shapiro1982algorithmic,lichtenstein1988concurrent,silverman1988logix}, as well as writing a GLP operating system in GLP~\cite{shapiro1984systems}. These two scenarios are the focus of this section:
a programmer developing a program and running it with enhanced metainterpreters that support the various needs of program development, and an operating system written in GLP that supports the execution, monitoring and and control of GLP programs.

\mypara{Plain metainterpreter}
Next we show a plain \glp metainterpreter.
It follows the standard granularity of logic programming metainterpreters, using the predicate \verb|reduce| to encode each program clause. This approach avoids the need for explicit renaming and, in the case of concurrent logic programs such as GLP also guard evaluation, while maintaining explicit goal reduction and body evaluation. The encoding is such that if in a call to \verb|reduce| a given goal unifies with its first argument then the body is returned in its second argument. Here we show it together with a \verb|reduce| encoding of \verb|merge|.

\Program{\glp plain metainterpreter}\label{program:meta}
\begin{small}
\begin{verbatim}
run(true).  % halt 
run((A,B)) :- run(A?), run(B?). % fork 
run(A) :- known(A) | reduce(A?,B), run(B?) %  reduce 

reduce(merge([X|Xs],Ys,[X?|Zs?]),merge(Xs?,Ys?,Zs)). 
reduce(merge(Xs,[Y|Ys],[Y?|Zs?]),merge(Xs?,Ys?,Zs)).
reduce(merge([],[],[]),true). 
\end{verbatim}
\end{small}
 
 
For example, when called with an initial goal:
\begin{small}
\begin{verbatim}
run((merge([1,2,3],[4,5],Xs), merge([a,b],[c,d,e],Ys), merge(Xs?,Ys?,Zs)).
\end{verbatim}
\end{small}
after two forks using the second clause of \verb|run|, its goal would become:
\begin{small}
\begin{verbatim}
run((merge([1,2,3],[4,5],Xs)), run(merge([a,b],[c,d,e],Ys)), run(merge(Xs?,Ys?,Zs)).
\end{verbatim}
\end{small}
and its finite run would produce some merge of the four input lists.


\mypara{Fail-safe metainterpreter}
%
The operational semantics of Logic Programs and Grassroots Logic Programs specifies that a run is aborted once a goal fails.  Following this rule would make impossible the writing in GLP of a metainterpreter that identifies and diagnoses failure.  The following metainterpreter addresses this by assuming that the  representation of the interpreted program ends with the clause:
\begin{verbatim}
reduce(A,failed(A)) :- otherwise | true.
\end{verbatim}
Returning the failed goal \verb|A| as the term \verb|failed(A)| for further processing, the simplest being just reporting the failure, as in the following metainterpreter:

\Program{\glp fail-safe metainterpreter}\label{program:meta-failsafe}
\begin{small}
\begin{verbatim}
run(true,[]).  % halt 
run((A,B),Zs?) :- run(A?,Xs), run(B?,Ys), merge(Xs?,Ys?,Zs). % fork
run(fail(A),[fail(A?)]).    % report failure 
run(A,Xs?) :- known(A) | reduce(A?,B), run(B?,Xs) %  reduce 
\end{verbatim}
\end{small}

Failure reports can be used to debug a program, but do not prevent a faulty run from running forever.  

\mypara{Metainterpreter with run control}
%
Here we augment the metainterpreter with run control, via which a run can be suspended, resumed, and aborted. 
As control messages are intended to be ground, the control stream of a run can be distributed to all metainterpreter instances that participate in its execution.

\Program{\glp metainterpreter with run control}\label{program:meta-control}
\begin{small}
\begin{verbatim}
run(true,_).  % halt 
run((A,B),Cs) :- distribute(Cs?,Cs1,Cs2), run(A?,Cs1?), run(B?,Cs1). % fork
run(A,[suspend|Cs]) :- suspended_run(A,Cs?).   % suspend
run(A,Cs) :- known(A) |        % reduce
        distribute(Cs?,Cs1,Cs2), reduce(A?,B,Cs1?), run(B?,Xs,Cs2?). 

suspended_run(A,[resume|Cs]) :- run(A,Cs?).  
suspended_run(A,[abort|Cs]).
\end{verbatim}
\end{small}
The metainterpreter suspends reductions as soon as the control stream is bound to \verb=[suspend|Cs?]=, upon which the run can be resumed or aborted by binding \verb|Cs| accordingly. 
Combining Programs \ref{program:meta-failsafe} and \ref{program:meta-control} would allow the programmer to abort the run as soon as a goal fails.
But we wish to introduce additional capabilities before integrating them all.


\mypara{Termination detection} The following metainterpreter allows the detection of the termination of a concurrent GLP program.  It uses the `short-circuit' technique, in which a chain of paired variables extends while goals fork, contracts when goals terminate, and closes when all goals have terminated.

\Program{\glp termination-detecting metainterpreter}\label{program:meta-control}
\begin{small}
\begin{verbatim}
run(true,L,L?).  % halt 
run((A,B),Cs,L,R?) :-  run(A?,Cs1?,L?,M), run(B?,Cs1,M?,R). % fork
run(A,L,R?) :- known(A) |        % reduce
        reduce(A?,B,Cs1?), run(B?,Xs,Cs2?,L?,R). 
\end{verbatim}
\end{small}

When called with \verb|run(A,done,R)|, the reader \verb|R?| will be bound to \verb|done| iff the run terminates.  


\mypara{Collecting a snapshot of an aborted run}
The short-circuit technique can be used to extend the metainterpreter with run control to collect a snapshot of the run, if aborted before termination.  Upon abort,  
the resolvent is passed from left to right in the short circuit, with each metainterpreter instance adding their interpreted goal to the growing resolvent.
We only show the \verb|suspended_run| procedure:

\Program{\glp metainterpreter with run control and snapshot collection}\label{program:meta-control-abort-snapshot}
\begin{small}
\begin{verbatim}
suspended_run(A,[resume|Cs],L,R?) :- run(A,Cs?,L?,R).
suspended_run(A,[abort|_],L,[A?|L?]).
\end{verbatim}
\end{small}

When called with \verb|run(A,Cs?,[],R)|, if \verb|Cs| is bound to \verb|[suspend,abort]|, the reader \verb|R?| will be bound to the current resolvent of the run (which could be empty if the run has already terminated before

Note that taking a snapshot of a suspended run and then resuming it requires extra effort, as two copies of the goal are needed,  a `frozen' one for the snapshot, and a `live' one to continue the run.  Addressing this is necessary for interactive debugging, to allow a developer to watch a program under development as it runs.  We discuss it below.


\mypara{Producing a trace of a run} Tracing a run of a program and then single-stepping through its critical sections are basic debugging techniques, but applying them to concurrent programs is both difficult and less useful due to their nondeterminism.  Here is a metainterpreter that produces a trace of the run, which can then be used by a retracing  metainterpreter to single-step through the very same run, making the same nondeterministic scheduling choices.
It assumes that each program clause \verb= A:- D | B= is represented by a unit clause
\verb=reduce(A,B,I) :- G | true=, with $I$ being the serial number of the clause in the program.

\Program{\glp a tracing metainterpreter}\label{program:metatree}
\begin{small}
\begin{verbatim}
run(true,true).  % halt 
run((A,B),(TA?,TB?)) :- run(A?,TA), run(B?,TB). % fork 
run(A,((I?:Time?):-TB?)) :- known(A) | 
    time(Time), reduce(A?,B,I), run(B?, TB).
\end{verbatim}
\end{small}


As another example, here is a \glp metainterpreter, inspired by~\cite{shapiro1984systems}, that can suspend, resume, and abort a \glp run and produce a dump of the processes of the aborted run. It employs the guard predicate \verb|otherwise|, which succeeds if and only if all previous clauses in the procedure fail (as opposed to suspend). This enables default case handling when no other clause applies.

\Program{\glp metainterpreter with runtime control}\label{program:runtime}
\begin{small}
\begin{verbatim}
run(true,Cs,L?,L).  % halt and close the dump
run((A,B),Cs,L?,R) :- run(A?,Cs?,L,M?), run(B?,Cs?,M,R?). % fork 
run(A,Cs,L?,R) :- otherwise, unknown(Cs) | reduce(A?,B), run(B?,Cs,L,R?) %  reduce 
run(A,[abort|Cs],[A?|R?],R). % abort and dump 
run(A,[suspend|Cs],L?,R) :- suspended_run(A?,Cs?,L,R?). % suspend

suspended_run(A,[resume|Cs],L?,R) :-  run(A?,Cs?,L,R?).  % resume
suspended_run(A,[C|Cs],L?,R) :- otherwise | run(A?,[C?|Cs?],L,R?).
\end{verbatim}
\end{small}

Its first argument is the process (goal) to be executed, its second argument \verb|Cs| is the observed interrupt stream, and its last two arguments form a `difference-list', a standard logic programming technique~\cite{sterling1994art} by which a list can be accumulated in a distributed way (the program is not fail-stop resilient; it can be extended to be so). 
 

\section{Bytecode Instruction Reference}\label{appendix:bytecode-reference}

This appendix provides a complete reference for the GLP bytecode instruction set v2.16, as implemented in the Dart runtime.

\subsection{Instruction Categories}

\mypara{Control Instructions}
\begin{itemize}
\item \textbf{clause\_try}: Initialize clause attempt, clear tentative state ($\hat{\sigma}_w = \emptyset$, $S_i = \emptyset$)
\item \textbf{clause\_next L}: On failure/suspension, jump to label L for next clause
\item \textbf{commit}: Apply tentative bindings atomically, activate suspended goals
\item \textbf{suspend}: Create suspension note for unbound readers in U
\item \textbf{proceed}: Return from procedure call
\end{itemize}

\mypara{Head Instructions (Phase 1)}
\begin{itemize}
\item \textbf{head\_bind\_writer W}: Tentatively bind writer W (adds to $\hat{\sigma}_w$)
\item \textbf{head\_need\_reader R}: Add reader R to suspension set $S_i$
\item \textbf{head\_structure f/n, Ai}: Process structure in register Ai
\item \textbf{head\_list Ai}: Process list in register Ai
\item \textbf{require\_writer\_arg slot, fail}: Verify argument slot contains writer
\item \textbf{require\_reader\_arg slot, fail}: Verify argument slot contains reader
\end{itemize}

\mypara{Body Instructions (Phase 2)}
\begin{itemize}
\item \textbf{body\_set\_const W, value}: Bind writer W to constant (post-commit)
\item \textbf{put\_structure f/n, Ai}: Create structure in register Ai
\item \textbf{put\_list Ai}: Create list in register Ai
\item \textbf{allocate n}: Create environment frame for n permanent variables
\item \textbf{deallocate}: Remove environment frame
\end{itemize}

\mypara{Unification Instructions}
\begin{itemize}
\item \textbf{unify\_writer W}: Unify with writer in READ mode
\item \textbf{unify\_reader R}: Verify reader matches in READ mode
\item \textbf{unify\_constant c}: Unify with constant
\item \textbf{unify\_value Xi}: Unify with value in register Xi
\end{itemize}

\mypara{Call Instructions}
\begin{itemize}
\item \textbf{call p/n}: Call procedure p with arity n
\item \textbf{execute p/n}: Tail call (deallocate then call)
\item \textbf{spawn p/n}: Create new goal for procedure p/n
\item \textbf{requeue p/n}: Replace current goal with call to p/n
\end{itemize}

\subsection{Phase Discipline}

All instructions respect the two-phase execution model:

\textbf{Phase 1 (HEAD/GUARDS)}: 
\begin{itemize}
\item No heap mutations
\item Collect tentative bindings in $\hat{\sigma}_w$
\item Build suspension set in $S_i$
\item May fail or suspend
\end{itemize}

\textbf{Phase 2 (BODY)}: 
\begin{itemize}
\item After commit point
\item Direct heap mutations allowed
\item Can allocate/deallocate frames
\item Cannot fail (only suspend)
\end{itemize}

\subsection{Register Architecture}

\begin{center}
\begin{tabular}{ll}
\hline
\textbf{Register} & \textbf{Purpose} \\
\hline
A1...An & Argument registers for procedure calls \\
X1...Xn & Temporary registers (clause-local) \\
Y1...Yn & Permanent registers (in environment) \\
PC & Program counter \\
CP & Continuation pointer \\
E & Environment pointer \\
S & Structure pointer \\
Mode & Unification mode (READ/WRITE) \\
$\kappa$ & Procedure entry point (for suspension) \\
\hline
\end{tabular}
\end{center}

\section{Runtime Architecture}\label{appendix:runtime-architecture}

The GLP runtime system consists of several interconnected components that collectively implement the language's execution model.

\subsection{System Overview}

The runtime architecture follows a layered design:

\begin{verbatim}
┌─────────────────────────────────────────────┐
│          User GLP Program                  │
├─────────────────────────────────────────────┤
│          Bytecode Layer                    │
│  ┌──────────────┐  ┌──────────────┐       │
│  │   Compiler   │  │   Runner     │       │
│  └──────────────┘  └──────────────┘       │
├─────────────────────────────────────────────┤
│          Runtime System                    │
│  ┌──────────────┐  ┌──────────────┐       │
│  │     Heap     │  │   Scheduler  │       │
│  ├──────────────┤  ├──────────────┤       │
│  │     ROQ      │  │  Goal Queue  │       │
│  ├──────────────┤  ├──────────────┤       │
│  │    Terms     │  │   Fairness   │       │
│  └──────────────┘  └──────────────┘       │
├─────────────────────────────────────────────┤
│          Dart Runtime                      │
│    (Event Loop, Microtasks, GC)           │
└─────────────────────────────────────────────┘
\end{verbatim}

\subsection{Component Descriptions}

\mypara{Heap Management}
\begin{itemize}
\item Manages writer/reader cell pairs
\item Enforces single-assignment semantics
\item Tracks variable bindings and dereferencing chains
\item Maintains SRSW invariant
\end{itemize}

\mypara{Goal Scheduler}
\begin{itemize}
\item FIFO queue of active goals
\item Integrates with Dart's microtask queue
\item Implements fairness through tail recursion budgets
\item Manages goal states (Active, Suspended, Failed)
\end{itemize}

\mypara{ROQ (Read-Only Queue)}
\begin{itemize}
\item Maps readers to suspended goals
\item FIFO wake order per reader
\item Processes activations on variable binding
\item Handles abandonment notifications
\end{itemize}

\mypara{Bytecode Runner}
\begin{itemize}
\item Interprets bytecode instructions
\item Manages execution context per goal
\item Implements two-phase execution model
\item Handles suspension and reactivation
\end{itemize}

\subsection{Execution Flow}

\begin{enumerate}
\item \textbf{Goal Creation}: New goals enter the active queue
\item \textbf{Scheduling}: Scheduler dequeues next active goal
\item \textbf{Reduction}: Runner executes bytecode until:
   \begin{itemize}
   \item Success: Goal completes
   \item Suspension: Goal waits on readers
   \item Failure: Goal permanently fails
   \item Yield: Tail budget exhausted
   \end{itemize}
\item \textbf{Variable Binding}: Triggers ROQ processing
\item \textbf{Reactivation}: Suspended goals return to active queue
\item \textbf{Repeat}: Continue until no active goals remain
\end{enumerate}

\subsection{Memory Model}

The runtime uses Dart's garbage collection with careful management of:
\begin{itemize}
\item \textbf{Strong References}: Active goals, bound variables
\item \textbf{Weak References}: Suspended goals (where appropriate)
\item \textbf{Cleanup}: Abandoned variables, failed goals
\end{itemize}

\section{Compiler Design Specification}\label{appendix:compiler-design}

This appendix specifies the design of the GLP compiler that translates source programs to bytecode.

\subsection{Compiler Pipeline}

The compilation process consists of four main phases:

\begin{enumerate}
\item \textbf{Lexical Analysis}: Source text → Token stream
\item \textbf{Parsing}: Tokens → Abstract Syntax Tree (AST)
\item \textbf{Semantic Analysis}: AST → Annotated AST with SRSW verification
\item \textbf{Code Generation}: Annotated AST → Bytecode
\end{enumerate}

\subsection{Parser Specification}

\mypara{Grammar (EBNF)}
\begin{verbatim}
program     ::= clause+
clause      ::= head [':-' body] '.'
head        ::= atom
body        ::= goal [',' goal]*
goal        ::= atom
atom        ::= functor ['(' term [',' term]* ')']
term        ::= variable | reader | constant | structure | list
variable    ::= [A-Z][a-zA-Z0-9_]*
reader      ::= variable '?'
constant    ::= [a-z][a-zA-Z0-9_]* | number | string
structure   ::= functor '(' term [',' term]* ')'
list        ::= '[' [term [',' term]*] ['|' term] ']'
functor     ::= [a-z][a-zA-Z0-9_]*
\end{verbatim}

\mypara{AST Node Types}
\begin{itemize}
\item \textbf{ProgramNode}: List of procedures
\item \textbf{ProcedureNode}: Predicate name/arity, list of clauses
\item \textbf{ClauseNode}: Head, optional guard, body
\item \textbf{AtomNode}: Functor, arguments
\item \textbf{TermNode}: Variable, constant, structure, or list
\item \textbf{VariableNode}: Name, type (reader/writer)
\end{itemize}

\subsection{Semantic Analysis}

\mypara{SRSW Verification}
The analyzer must verify for each clause:
\begin{enumerate}
\item Each variable appears at most once as a writer
\item Each variable appears at most once as a reader
\item No variable appears as both reader and writer in different positions
\item Ground guard permits multiple reader occurrences
\end{enumerate}

\mypara{Variable Classification}
\begin{itemize}
\item \textbf{Temporary}: Used only within a clause
\item \textbf{Permanent}: Spans across goals in body
\item \textbf{Argument}: Passed between procedures
\item \textbf{Void}: Single occurrence (anonymous)
\end{itemize}

\mypara{Mode Analysis}
Determine for each predicate argument position:
\begin{itemize}
\item \textbf{Input (+)}: Always instantiated on call
\item \textbf{Output (-)}: Always uninstantiated on call
\item \textbf{Unknown (?)}: May be either
\end{itemize}

\subsection{Code Generation}

\mypara{Clause Compilation Strategy}
\begin{enumerate}
\item Generate label for clause entry
\item Emit \texttt{clause\_try}
\item Compile head pattern matching
\item Compile guard (if present)
\item Emit \texttt{commit}
\item Allocate environment (if needed)
\item Compile body goals
\item Deallocate and proceed
\item Handle failure with \texttt{clause\_next}
\end{enumerate}

\mypara{Head Compilation}
\begin{itemize}
\item Arguments → Get operations in READ mode
\item New variables → Put operations in WRITE mode
\item Structures → Recursive unification
\item Lists → Special list instructions
\end{itemize}

\mypara{Body Compilation}
\begin{itemize}
\item Build arguments in A registers
\item Call procedures with proper continuation
\item Tail calls use \texttt{execute}
\item Non-tail calls use \texttt{call}
\end{itemize}

\subsection{Optimization Opportunities}

\mypara{Phase 1 (Initial Implementation)}
\begin{itemize}
\item No optimizations
\item Focus on correctness
\item Generate readable bytecode
\end{itemize}

\mypara{Phase 2 (Basic Optimizations)}
\begin{itemize}
\item Dead code elimination
\item Constant folding
\item Tail call optimization
\item Register allocation
\end{itemize}

\mypara{Phase 3 (Advanced Optimizations)}
\begin{itemize}
\item Clause indexing
\item Argument specialization
\item Inline expansion
\item Partial evaluation
\end{itemize}

\subsection{Error Handling}

The compiler must provide clear error messages for:
\begin{itemize}
\item Syntax errors with line/column information
\item SRSW violations with variable occurrence details
\item Undefined predicates with suggestions
\item Type mismatches in built-in operations
\item Guard purity violations
\end{itemize}

\subsection{Module System Integration}

\mypara{Module Compilation}
\begin{itemize}
\item Each module compiles to separate bytecode segment
\item Export table lists public predicates
\item Import table lists required predicates
\item Symbol table maps names to addresses
\end{itemize}

\mypara{Linking}
\begin{itemize}
\item Resolve inter-module predicate references
\item Verify export/import consistency
\item Merge bytecode segments
\item Generate unified symbol table
\end{itemize}

\end{document}